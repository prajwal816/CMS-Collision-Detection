{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14853876,"sourceType":"datasetVersion","datasetId":9500718}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# EDA: CMS DoubleMuon Run2016G (NanoAOD) — Dataset Understanding\n\n**Goal:** Parse the `index.json_*` files to obtain a file list, then stream a small sample of NanoAOD ROOT files and perform EDA:\n- dataset manifest (how many files, what paths)\n- NanoAOD structure (trees, branches, collections)\n- event-level EDA (run/lumi, PV, MET)\n- muon & dimuon EDA (multiplicities, kinematics, invariant mass peaks)\n- trigger (HLT_*) inventory and basic rates\n\nWe will keep everything reproducible and “CERN-reviewable”:\n- deterministic sampling (seed)\n- minimal assumptions about the index file format (we detect and adapt)\n- no full downloads required; we read only a limited number of events for EDA\n","metadata":{}},{"cell_type":"code","source":"# Cell 1 — Install (safe to run even if already installed)\n# If you only have local ROOT files (not remote), XRootD may not be necessary.\n!pip -q install \"uproot>=5\" awkward vector rich tqdm pandas pyarrow fastparquet\ntry:\n    import XRootD  # noqa: F401\nexcept Exception:\n    # Needed only for root:// streaming. If this fails, you can still analyze local files.\n    !pip -q install XRootD\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-16T08:10:18.099845Z","iopub.execute_input":"2026-02-16T08:10:18.100066Z","iopub.status.idle":"2026-02-16T08:10:32.510938Z","shell.execute_reply.started":"2026-02-16T08:10:18.100045Z","shell.execute_reply":"2026-02-16T08:10:32.510066Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.8/393.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m919.6/919.6 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m656.7/656.7 kB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.2/181.2 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n  \n  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for XRootD \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n  \u001b[31m╰─>\u001b[0m See above for output.\n  \n  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n  Building wheel for XRootD (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n\u001b[31m  ERROR: Failed building wheel for XRootD\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (XRootD)\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Cell 3 — Locate index files\nindex_files = []\nfor x in INDEX_SUFFIXES:\n    # Match anything that ends with index.json_x\n    # Example: CMS_Run2016G_..._file_index.json_0\n    pattern = re.compile(rf\"index\\.json_{x}$\")\n    for p in BASE_PATH.rglob(\"*\"):\n        if p.is_file() and pattern.search(p.name):\n            index_files.append(p)\n\nindex_files = sorted(index_files)\nindex_files, len(index_files)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T08:10:32.512853Z","iopub.execute_input":"2026-02-16T08:10:32.513110Z","iopub.status.idle":"2026-02-16T08:10:32.523930Z","shell.execute_reply.started":"2026-02-16T08:10:32.513082Z","shell.execute_reply":"2026-02-16T08:10:32.522032Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/2802366417.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Cell 3 — Locate index files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mindex_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mINDEX_SUFFIXES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Match anything that ends with index.json_x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Example: CMS_Run2016G_..._file_index.json_0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'INDEX_SUFFIXES' is not defined"],"ename":"NameError","evalue":"name 'INDEX_SUFFIXES' is not defined","output_type":"error"}],"execution_count":2},{"cell_type":"code","source":"# Cell 4 — Helper: robust index parser\n# We don't assume a single JSON schema; we try:\n# 1) JSON list/dict\n# 2) JSON Lines\n# 3) plain text (one file per line)\n#\n# We extract anything that looks like a ROOT file path/URL (endswith .root).\n\ndef extract_root_paths(obj):\n    \"\"\"Recursively extract .root strings from nested dict/list.\"\"\"\n    out = []\n    if isinstance(obj, str):\n        if obj.strip().endswith(\".root\") or \".root?\" in obj:\n            out.append(obj.strip())\n    elif isinstance(obj, dict):\n        for v in obj.values():\n            out.extend(extract_root_paths(v))\n    elif isinstance(obj, list):\n        for it in obj:\n            out.extend(extract_root_paths(it))\n    return out\n\ndef parse_index_file(path: Path, max_lines=None):\n    # Peek first non-empty char to guess format\n    with path.open(\"rb\") as f:\n        head = f.read(4096)\n    head_text = head.decode(\"utf-8\", errors=\"ignore\").lstrip()\n    first_char = head_text[:1]\n\n    roots = []\n\n    # Case A: JSON container\n    if first_char in [\"{\", \"[\"]:\n        try:\n            with path.open(\"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n                data = json.load(f)\n            roots = extract_root_paths(data)\n            return roots, \"json\"\n        except Exception:\n            pass\n\n    # Case B: JSON lines or plain text lines\n    roots = []\n    with path.open(\"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n        for i, line in enumerate(f):\n            if max_lines is not None and i >= max_lines:\n                break\n            s = line.strip()\n            if not s:\n                continue\n            # Try JSON line\n            if s[0] in [\"{\", \"[\"]:\n                try:\n                    data = json.loads(s)\n                    roots.extend(extract_root_paths(data))\n                    continue\n                except Exception:\n                    pass\n            # Fallback: treat as plain text and extract any token that looks like a ROOT file\n            # e.g. \"root://.../file.root\" or \"/eos/.../file.root\"\n            m = re.findall(r\"(\\S+?\\.root(?:\\?\\S+)?)\", s)\n            roots.extend(m)\n\n    kind = \"jsonl_or_text\"\n    return roots, kind\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T08:10:32.524396Z","iopub.status.idle":"2026-02-16T08:10:32.524683Z","shell.execute_reply.started":"2026-02-16T08:10:32.524534Z","shell.execute_reply":"2026-02-16T08:10:32.524548Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 5 — Build a file manifest from all index files\nall_roots = []\nparse_meta = []\n\nfor p in index_files:\n    roots, kind = parse_index_file(p)\n    parse_meta.append({\"index_file\": str(p), \"parse_kind\": kind, \"n_root_paths\": len(roots)})\n    all_roots.extend(roots)\n\nmeta_df = pd.DataFrame(parse_meta)\nmeta_df\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T08:10:32.525764Z","iopub.status.idle":"2026-02-16T08:10:32.526123Z","shell.execute_reply.started":"2026-02-16T08:10:32.525938Z","shell.execute_reply":"2026-02-16T08:10:32.525960Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 6 — Clean & de-duplicate ROOT paths\ndef normalize_path(s):\n    s = s.strip().strip('\"').strip(\"'\")\n    # Some indices include EOS paths without protocol. If you already have root:// paths, keep them.\n    # If it's a /eos/opendata/... path, you can turn it into root://eospublic.cern.ch//eos/opendata/...\n    if s.startswith(\"/eos/opendata/\"):\n        return \"root://eospublic.cern.ch//\" + s.lstrip(\"/\")\n    return s\n\nroots = [normalize_path(r) for r in all_roots]\nroots = [r for r in roots if r.endswith(\".root\") or \".root?\" in r]\nroots = pd.Series(roots).drop_duplicates().tolist()\n\nlen(roots), roots[:5]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T08:10:32.527971Z","iopub.status.idle":"2026-02-16T08:10:32.528244Z","shell.execute_reply.started":"2026-02-16T08:10:32.528129Z","shell.execute_reply":"2026-02-16T08:10:32.528149Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 7 — Save manifest (useful for debugging & reproducibility)\nmanifest = pd.DataFrame({\"root_file\": roots})\nmanifest_path = Path(\"/kaggle/working/root_files_manifest.csv\")\nmanifest.to_csv(manifest_path, index=False)\nmanifest_path, manifest.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T08:10:32.529364Z","iopub.status.idle":"2026-02-16T08:10:32.529767Z","shell.execute_reply.started":"2026-02-16T08:10:32.529586Z","shell.execute_reply":"2026-02-16T08:10:32.529607Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Quick sanity checks\n\nWe now:\n1. pick a small deterministic sample of ROOT files\n2. open one file to inspect available TTrees (usually: `Events`, sometimes `Runs`, `LuminosityBlocks`)\n3. inspect branches to decide which features are safe to use in EDA\n","metadata":{}},{"cell_type":"code","source":"# Cell 8 — Deterministic sampling of files for EDA\nN_FILES_FOR_EDA = 3   # start tiny\nsample_files = roots[:N_FILES_FOR_EDA]  # deterministic; you can also do random.sample(roots, N_FILES_FOR_EDA)\n\nsample_files\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T08:10:32.531174Z","iopub.status.idle":"2026-02-16T08:10:32.531438Z","shell.execute_reply.started":"2026-02-16T08:10:32.531313Z","shell.execute_reply":"2026-02-16T08:10:32.531331Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 9 — Inspect a single file structure\ntest_file = sample_files[0]\nf = uproot.open(test_file)\n\nf.keys()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T08:10:32.533036Z","iopub.status.idle":"2026-02-16T08:10:32.533349Z","shell.execute_reply.started":"2026-02-16T08:10:32.533198Z","shell.execute_reply":"2026-02-16T08:10:32.533221Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 10 — Inspect Events tree & branch inventory\nevents = f[\"Events\"]\nbranch_names = events.keys()\n\nlen(branch_names), branch_names[:30]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T08:10:32.534768Z","iopub.status.idle":"2026-02-16T08:10:32.535037Z","shell.execute_reply.started":"2026-02-16T08:10:32.534896Z","shell.execute_reply":"2026-02-16T08:10:32.534918Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 11 — Helper to find branches by prefix (Muon_, HLT_, PV_, MET_, etc.)\ndef find_branches(prefix, names):\n    return sorted([n for n in names if n.startswith(prefix)])\n\nfor pref in [\"Muon_\", \"HLT_\", \"PV_\", \"MET_\", \"Jet_\", \"Electron_\", \"run\", \"luminosityBlock\", \"event\"]:\n    hits = [pref] if pref in branch_names else find_branches(pref, branch_names)\n    print(pref, \"->\", len(hits))\n    print(hits[:20], \"\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T08:10:32.536194Z","iopub.status.idle":"2026-02-16T08:10:32.536518Z","shell.execute_reply.started":"2026-02-16T08:10:32.536369Z","shell.execute_reply":"2026-02-16T08:10:32.536383Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Load a small event sample (EDA slice)\n\nWe will read a limited number of entries so EDA runs fast.  \nIf you see memory errors, reduce `ENTRY_STOP` or restrict to fewer branches.\n","metadata":{}},{"cell_type":"code","source":"# Cell 12 — Choose EDA branches (keep this minimal at first)\n# NanoAOD branch names are flat, like Muon_pt, Muon_eta (jagged arrays).\nBASE_BRANCHES = [\"run\", \"luminosityBlock\", \"event\", \"PV_npvs\", \"MET_pt\", \"MET_phi\"]\nMUON_BRANCHES = [\n    \"Muon_pt\", \"Muon_eta\", \"Muon_phi\", \"Muon_charge\",\n    \"Muon_tightId\", \"Muon_mediumId\",\n    \"Muon_pfRelIso03_all\", \"Muon_dxy\", \"Muon_dz\"\n]\n# Trigger inventory can be large; we’ll read a filtered set later.\n\nwanted = [b for b in (BASE_BRANCHES + MUON_BRANCHES) if b in branch_names]\nmissing = sorted(set(BASE_BRANCHES + MUON_BRANCHES) - set(wanted))\n\nwanted, missing[:20], len(missing)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T08:10:32.538100Z","iopub.status.idle":"2026-02-16T08:10:32.538385Z","shell.execute_reply.started":"2026-02-16T08:10:32.538242Z","shell.execute_reply":"2026-02-16T08:10:32.538255Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 13 — Read arrays from one file (small slice)\nENTRY_STOP = 200_000  # adjust as needed\n\narr = events.arrays(wanted, entry_stop=ENTRY_STOP, library=\"ak\")\n{ k: (arr[k].type if k in arr.fields else None) for k in arr.fields }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T08:10:32.540311Z","iopub.status.idle":"2026-02-16T08:10:32.540534Z","shell.execute_reply.started":"2026-02-16T08:10:32.540428Z","shell.execute_reply":"2026-02-16T08:10:32.540441Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 14 — Event-level EDA tables\ndf_evt = pd.DataFrame({\n    \"run\": ak.to_numpy(arr[\"run\"]),\n    \"lumi\": ak.to_numpy(arr[\"luminosityBlock\"]),\n    \"event\": ak.to_numpy(arr[\"event\"]),\n    \"PV_npvs\": ak.to_numpy(arr[\"PV_npvs\"]) if \"PV_npvs\" in arr.fields else np.nan,\n    \"MET_pt\": ak.to_numpy(arr[\"MET_pt\"]) if \"MET_pt\" in arr.fields else np.nan,\n})\n\ndf_evt.describe(include=\"all\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T08:10:32.541376Z","iopub.status.idle":"2026-02-16T08:10:32.541733Z","shell.execute_reply.started":"2026-02-16T08:10:32.541539Z","shell.execute_reply":"2026-02-16T08:10:32.541578Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 15 — Run/lumi coverage in the slice\ndf_evt[[\"run\", \"lumi\"]].value_counts().head(10)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T08:10:32.542745Z","iopub.status.idle":"2026-02-16T08:10:32.543090Z","shell.execute_reply.started":"2026-02-16T08:10:32.542909Z","shell.execute_reply":"2026-02-16T08:10:32.542930Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 16 — Muon multiplicity distribution\nmu_n = ak.num(arr[\"Muon_pt\"])\nmu_n_pd = pd.Series(ak.to_numpy(mu_n), name=\"nMuon\")\n\nmu_n_pd.value_counts().sort_index().head(20), mu_n_pd.describe()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T08:10:32.543993Z","iopub.status.idle":"2026-02-16T08:10:32.544239Z","shell.execute_reply.started":"2026-02-16T08:10:32.544120Z","shell.execute_reply":"2026-02-16T08:10:32.544139Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 17 — Basic muon kinematics (flatten all muons in the slice)\nmu_pt = ak.flatten(arr[\"Muon_pt\"])\nmu_eta = ak.flatten(arr[\"Muon_eta\"])\nmu_iso = ak.flatten(arr[\"Muon_pfRelIso03_all\"]) if \"Muon_pfRelIso03_all\" in arr.fields else None\n\nmu_summary = pd.DataFrame({\n    \"Muon_pt\": ak.to_numpy(mu_pt),\n    \"Muon_eta\": ak.to_numpy(mu_eta),\n    \"Muon_pfRelIso03_all\": ak.to_numpy(mu_iso) if mu_iso is not None else np.nan\n}).describe()\n\nmu_summary\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T08:10:32.545208Z","iopub.status.idle":"2026-02-16T08:10:32.545487Z","shell.execute_reply.started":"2026-02-16T08:10:32.545359Z","shell.execute_reply":"2026-02-16T08:10:32.545381Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 18 — Quick plots (matplotlib)\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(7,4))\nplt.hist(ak.to_numpy(mu_pt), bins=100, range=(0, 200), histtype=\"step\")\nplt.xlabel(\"Muon pT [GeV]\")\nplt.ylabel(\"Muons / bin\")\nplt.title(\"Muon pT (slice)\")\nplt.show()\n\nplt.figure(figsize=(7,4))\nplt.hist(ak.to_numpy(mu_eta), bins=60, range=(-3, 3), histtype=\"step\")\nplt.xlabel(\"Muon eta\")\nplt.ylabel(\"Muons / bin\")\nplt.title(\"Muon eta (slice)\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T08:10:32.546645Z","iopub.status.idle":"2026-02-16T08:10:32.547000Z","shell.execute_reply.started":"2026-02-16T08:10:32.546809Z","shell.execute_reply":"2026-02-16T08:10:32.546830Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Dimuon EDA (physics sanity check)\n\nA recruiter/engineer will trust your pipeline more if you demonstrate a correct dimuon invariant mass spectrum.  \nWe build opposite-sign muon pairs and plot the mass distribution; you should see structures consistent with known resonances in collision data.\n","metadata":{}},{"cell_type":"code","source":"# Cell 19 — Build dimuon pairs and invariant mass\nMUON_MASS = 0.105658  # GeV\n\nmu = vector.zip({\n    \"pt\": arr[\"Muon_pt\"],\n    \"eta\": arr[\"Muon_eta\"],\n    \"phi\": arr[\"Muon_phi\"],\n    \"mass\": ak.ones_like(arr[\"Muon_pt\"]) * MUON_MASS,\n    \"charge\": arr[\"Muon_charge\"],\n})\n\n# Basic quality selection (adjust after you inspect data):\n# - at least mediumId OR tightId if available\nqual = None\nif \"Muon_mediumId\" in arr.fields:\n    qual = (arr[\"Muon_mediumId\"] == 1)\nelif \"Muon_tightId\" in arr.fields:\n    qual = (arr[\"Muon_tightId\"] == 1)\nelse:\n    qual = ak.ones_like(arr[\"Muon_pt\"], dtype=bool)\n\nmu_sel = mu[qual]\n\npairs = ak.combinations(mu_sel, 2, fields=[\"m1\", \"m2\"])\nos_pairs = pairs[(pairs.m1.charge * pairs.m2.charge) < 0]\n\ndimu = os_pairs.m1 + os_pairs.m2\nm_mumu = ak.flatten(dimu.mass)\n\nlen(m_mumu), ak.to_numpy(m_mumu[:10])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T08:10:32.549641Z","iopub.status.idle":"2026-02-16T08:10:32.550052Z","shell.execute_reply.started":"2026-02-16T08:10:32.549870Z","shell.execute_reply":"2026-02-16T08:10:32.549899Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 20 — Plot dimuon mass spectrum\nplt.figure(figsize=(8,4))\nplt.hist(ak.to_numpy(m_mumu), bins=200, range=(0, 200), histtype=\"step\")\nplt.xlabel(\"m(μ⁺μ⁻) [GeV]\")\nplt.ylabel(\"Pairs / bin\")\nplt.title(\"Opposite-sign dimuon invariant mass (slice)\")\nplt.yscale(\"log\")\nplt.show()\n\n# Zoom around Z peak\nplt.figure(figsize=(8,4))\nplt.hist(ak.to_numpy(m_mumu), bins=120, range=(60, 120), histtype=\"step\")\nplt.xlabel(\"m(μ⁺μ⁻) [GeV]\")\nplt.ylabel(\"Pairs / bin\")\nplt.title(\"Zoom: Z region\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T08:10:32.551231Z","iopub.status.idle":"2026-02-16T08:10:32.551502Z","shell.execute_reply.started":"2026-02-16T08:10:32.551389Z","shell.execute_reply":"2026-02-16T08:10:32.551403Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Trigger inventory (HLT_) EDA\n\nWe’ll discover which `HLT_` branches exist in this file and then compute simple “fired fraction” estimates in our slice.\n","metadata":{}},{"cell_type":"code","source":"# Cell 21 — Enumerate HLT branches (from this file)\nhlt_branches = find_branches(\"HLT_\", branch_names)\nlen(hlt_branches), hlt_branches[:40]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T08:10:32.552731Z","iopub.status.idle":"2026-02-16T08:10:32.553105Z","shell.execute_reply.started":"2026-02-16T08:10:32.552918Z","shell.execute_reply":"2026-02-16T08:10:32.552938Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 22 — Read a small subset of HLT branches (filter to muon-ish names)\n# Keep only muon-related triggers to reduce I/O\nhlt_mu = [b for b in hlt_branches if (\"Mu\" in b or \"mu\" in b)][:60]  # cap for speed\n\nwanted2 = wanted + [b for b in hlt_mu if b not in wanted]\narr2 = events.arrays(wanted2, entry_stop=ENTRY_STOP, library=\"ak\")\n\n# Fired fraction table\nhlt_rate = []\nfor b in hlt_mu:\n    if b in arr2.fields:\n        frac = float(ak.mean(arr2[b]))\n        hlt_rate.append((b, frac))\n\nhlt_rate_df = pd.DataFrame(hlt_rate, columns=[\"HLT_path\", \"fired_fraction_in_slice\"]).sort_values(\n    \"fired_fraction_in_slice\", ascending=False\n)\n\nhlt_rate_df.head(25)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T08:10:32.553812Z","iopub.status.idle":"2026-02-16T08:10:32.554028Z","shell.execute_reply.started":"2026-02-16T08:10:32.553921Z","shell.execute_reply":"2026-02-16T08:10:32.553933Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Scale EDA to multiple ROOT files\n\nNow we repeat EDA across a few files to check stability (no single-file artifacts).  \nWe will:\n- read a small number of events from each file\n- compute summary metrics (nMuon mean, MET mean, dimuon-pair count, etc.)\n","metadata":{}},{"cell_type":"code","source":"# Cell 23 — Multi-file EDA summarizer\ndef summarize_file(root_path, entry_stop=100_000):\n    f = uproot.open(root_path)\n    t = f[\"Events\"]\n\n    # Keep branches minimal\n    branches = [b for b in [\"run\",\"luminosityBlock\",\"PV_npvs\",\"MET_pt\",\"Muon_pt\",\"Muon_eta\",\"Muon_phi\",\"Muon_charge\",\"Muon_mediumId\",\"Muon_tightId\"] if b in t.keys()]\n    a = t.arrays(branches, entry_stop=entry_stop, library=\"ak\")\n\n    nMuon = ak.num(a[\"Muon_pt\"])\n    mu_pt = ak.flatten(a[\"Muon_pt\"])\n\n    # Opposite-sign dimuons count (fast approximation)\n    mu_charge = a[\"Muon_charge\"]\n    # Count OS pairs by brute-force combinations (ok for small entry_stop)\n    mu_vec = vector.zip({\n        \"pt\": a[\"Muon_pt\"],\n        \"eta\": a[\"Muon_eta\"],\n        \"phi\": a[\"Muon_phi\"],\n        \"mass\": ak.ones_like(a[\"Muon_pt\"]) * MUON_MASS,\n        \"charge\": mu_charge,\n    })\n    pairs = ak.combinations(mu_vec, 2, fields=[\"m1\",\"m2\"])\n    os_pairs = pairs[(pairs.m1.charge * pairs.m2.charge) < 0]\n    nOSPairs = ak.num(os_pairs.m1)\n\n    out = {\n        \"file\": root_path,\n        \"nEvents\": len(a[\"run\"]) if \"run\" in a.fields else len(a[\"Muon_pt\"]),\n        \"run_min\": int(ak.min(a[\"run\"])) if \"run\" in a.fields else None,\n        \"run_max\": int(ak.max(a[\"run\"])) if \"run\" in a.fields else None,\n        \"nMuon_mean\": float(ak.mean(nMuon)),\n        \"nMuon_p95\": float(np.quantile(ak.to_numpy(nMuon), 0.95)),\n        \"mu_pt_mean\": float(ak.mean(mu_pt)),\n        \"mu_pt_p95\": float(np.quantile(ak.to_numpy(mu_pt), 0.95)),\n        \"MET_mean\": float(ak.mean(a[\"MET_pt\"])) if \"MET_pt\" in a.fields else np.nan,\n        \"nOSPairs_mean\": float(ak.mean(nOSPairs)),\n    }\n    return out\n\nsummaries = []\nfor fp in tqdm(sample_files, desc=\"Summarizing files\"):\n    summaries.append(summarize_file(fp, entry_stop=80_000))\n\nsum_df = pd.DataFrame(summaries)\nsum_df\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T08:10:32.555394Z","iopub.status.idle":"2026-02-16T08:10:32.555741Z","shell.execute_reply.started":"2026-02-16T08:10:32.555553Z","shell.execute_reply":"2026-02-16T08:10:32.555592Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 24 — Save EDA summary\nsum_path = Path(\"/kaggle/working/eda_file_summaries.csv\")\nsum_df.to_csv(sum_path, index=False)\nsum_path\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T08:10:32.556980Z","iopub.status.idle":"2026-02-16T08:10:32.557336Z","shell.execute_reply.started":"2026-02-16T08:10:32.557161Z","shell.execute_reply":"2026-02-16T08:10:32.557180Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Next step after EDA (prepare for the project)\n\nAfter you confirm:\n- your dimuon mass spectrum looks sensible\n- muon multiplicities are stable across files\n- you understand which HLT paths exist and have non-trivial fired fractions\n\n…then you can lock the project objective:\n**“Explainable trigger emulation + drift monitoring”**:\n- choose 3–6 HLT paths as labels\n- build a Parquet training table from a validated run/lumi selection\n- train an interpretable baseline + GBDT\n- add drift detection over run/lumi blocks\n","metadata":{}},{"cell_type":"code","source":"# Cell 25 — (Optional) Export a small Kaggle-ready Parquet slice for ML iteration\n# This is NOT your final dataset, just a development slice.\n\nout_parquet = Path(\"/kaggle/working/dev_slice.parquet\")\n\n# Flatten per-muon rows (common ML format). Keep run/lumi/event as keys.\n# NOTE: this duplicates event-level info for each muon; that’s fine for quick iteration.\nflat = ak.zip({\n    \"run\": arr2[\"run\"],\n    \"lumi\": arr2[\"luminosityBlock\"],\n    \"event\": arr2[\"event\"],\n    \"PV_npvs\": arr2[\"PV_npvs\"] if \"PV_npvs\" in arr2.fields else ak.zeros_like(arr2[\"run\"]),\n    \"MET_pt\": arr2[\"MET_pt\"] if \"MET_pt\" in arr2.fields else ak.zeros_like(arr2[\"run\"]),\n    \"Muon_pt\": arr2[\"Muon_pt\"],\n    \"Muon_eta\": arr2[\"Muon_eta\"],\n    \"Muon_phi\": arr2[\"Muon_phi\"],\n    \"Muon_charge\": arr2[\"Muon_charge\"],\n    \"Muon_mediumId\": arr2[\"Muon_mediumId\"] if \"Muon_mediumId\" in arr2.fields else ak.zeros_like(arr2[\"Muon_charge\"]),\n    \"Muon_tightId\": arr2[\"Muon_tightId\"] if \"Muon_tightId\" in arr2.fields else ak.zeros_like(arr2[\"Muon_charge\"]),\n    \"Muon_iso\": arr2[\"Muon_pfRelIso03_all\"] if \"Muon_pfRelIso03_all\" in arr2.fields else ak.zeros_like(arr2[\"Muon_pt\"]),\n})\n\nflat_rows = ak.flatten(flat, axis=1)\ndf_flat = ak.to_dataframe(flat_rows).reset_index(drop=True)\n\n# Add a couple of HLT labels (if present)\nfor b in hlt_mu[:10]:\n    if b in arr2.fields:\n        df_flat[b] = np.repeat(ak.to_numpy(arr2[b]), ak.to_numpy(ak.num(arr2[\"Muon_pt\"])))\n\ndf_flat.to_parquet(out_parquet, index=False)\nout_parquet, df_flat.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T08:10:32.558055Z","iopub.status.idle":"2026-02-16T08:10:32.558285Z","shell.execute_reply.started":"2026-02-16T08:10:32.558177Z","shell.execute_reply":"2026-02-16T08:10:32.558191Z"}},"outputs":[],"execution_count":null}]}