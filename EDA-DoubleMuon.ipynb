{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14857240,"sourceType":"datasetVersion","datasetId":9503642}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# EDA: DoubleMuon2016G (Local ROOT files)\n\n**Base path:** `/kaggle/input/datasets/katakuricharlotte/doublemuon2016g-rootfiles/root_converted`\n\nWe will:\n1. List ROOT files and sanity-check sizes\n2. Inspect NanoAOD structure (`Events` tree, branches)\n3. Read a small slice (`entry_stop`) for fast EDA\n4. Do event-level + muon-level + dimuon invariant mass EDA\n5. Inventory `HLT_*` triggers and estimate fired fractions\n6. Repeat quick summaries across multiple ROOT files to check stability\n","metadata":{}},{"cell_type":"code","source":"# Cell 1 — Install Python deps (no XRootD)\n!pip -q install \"uproot>=5\" awkward vector rich tqdm pandas pyarrow fastparquet matplotlib\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-16T10:01:47.006569Z","iopub.execute_input":"2026-02-16T10:01:47.006868Z","iopub.status.idle":"2026-02-16T10:01:54.259474Z","shell.execute_reply.started":"2026-02-16T10:01:47.006845Z","shell.execute_reply":"2026-02-16T10:01:54.258745Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.8/393.8 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m919.6/919.6 kB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m656.7/656.7 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.2/181.2 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Cell 2 — Imports & config\nimport os, re, json, random\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm.auto import tqdm\n\nimport awkward as ak\nimport uproot\nimport vector\n\nvector.register_awkward()\n\nBASE_PATH = Path(\"/kaggle/input/datasets/katakuricharlotte/doublemuon2016g-rootfiles/root_converted\")\nINDEX_SUFFIXES = [0, 1, 10, 11, 12]  # as you specified\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\n\nBASE_PATH\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T10:01:54.261581Z","iopub.execute_input":"2026-02-16T10:01:54.262294Z","iopub.status.idle":"2026-02-16T10:01:55.434702Z","shell.execute_reply.started":"2026-02-16T10:01:54.262263Z","shell.execute_reply":"2026-02-16T10:01:55.433952Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"PosixPath('/kaggle/input/datasets/katakuricharlotte/doublemuon2016g')"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"# Cell 3 — Locate index files\nindex_files = []\nfor x in INDEX_SUFFIXES:\n    # Match anything that ends with index.json_x\n    # Example: CMS_Run2016G_..._file_index.json_0\n    pattern = re.compile(rf\"index\\.json_{x}$\")\n    for p in BASE_PATH.rglob(\"*\"):\n        if p.is_file() and pattern.search(p.name):\n            index_files.append(p)\n\nindex_files = sorted(index_files)\nindex_files, len(index_files)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T10:01:55.435802Z","iopub.execute_input":"2026-02-16T10:01:55.436286Z","iopub.status.idle":"2026-02-16T10:01:55.457675Z","shell.execute_reply.started":"2026-02-16T10:01:55.436264Z","shell.execute_reply":"2026-02-16T10:01:55.455811Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"([PosixPath('/kaggle/input/datasets/katakuricharlotte/doublemuon2016g/CMS_Run2016G_DoubleMuon_NANOAOD_UL2016_MiniAODv2_NanoAODv9-v2_2430000_file_index.json_0'),\n  PosixPath('/kaggle/input/datasets/katakuricharlotte/doublemuon2016g/CMS_Run2016G_DoubleMuon_NANOAOD_UL2016_MiniAODv2_NanoAODv9-v2_2430000_file_index.json_1'),\n  PosixPath('/kaggle/input/datasets/katakuricharlotte/doublemuon2016g/CMS_Run2016G_DoubleMuon_NANOAOD_UL2016_MiniAODv2_NanoAODv9-v2_2430000_file_index.json_10'),\n  PosixPath('/kaggle/input/datasets/katakuricharlotte/doublemuon2016g/CMS_Run2016G_DoubleMuon_NANOAOD_UL2016_MiniAODv2_NanoAODv9-v2_2430000_file_index.json_11'),\n  PosixPath('/kaggle/input/datasets/katakuricharlotte/doublemuon2016g/CMS_Run2016G_DoubleMuon_NANOAOD_UL2016_MiniAODv2_NanoAODv9-v2_2430000_file_index.json_12')],\n 5)"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# Cell 4 — Helper: robust index parser\n# We don't assume a single JSON schema; we try:\n# 1) JSON list/dict\n# 2) JSON Lines\n# 3) plain text (one file per line)\n#\n# We extract anything that looks like a ROOT file path/URL (endswith .root).\n\ndef extract_root_paths(obj):\n    \"\"\"Recursively extract .root strings from nested dict/list.\"\"\"\n    out = []\n    if isinstance(obj, str):\n        if obj.strip().endswith(\".root\") or \".root?\" in obj:\n            out.append(obj.strip())\n    elif isinstance(obj, dict):\n        for v in obj.values():\n            out.extend(extract_root_paths(v))\n    elif isinstance(obj, list):\n        for it in obj:\n            out.extend(extract_root_paths(it))\n    return out\n\ndef parse_index_file(path: Path, max_lines=None):\n    # Peek first non-empty char to guess format\n    with path.open(\"rb\") as f:\n        head = f.read(4096)\n    head_text = head.decode(\"utf-8\", errors=\"ignore\").lstrip()\n    first_char = head_text[:1]\n\n    roots = []\n\n    # Case A: JSON container\n    if first_char in [\"{\", \"[\"]:\n        try:\n            with path.open(\"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n                data = json.load(f)\n            roots = extract_root_paths(data)\n            return roots, \"json\"\n        except Exception:\n            pass\n\n    # Case B: JSON lines or plain text lines\n    roots = []\n    with path.open(\"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n        for i, line in enumerate(f):\n            if max_lines is not None and i >= max_lines:\n                break\n            s = line.strip()\n            if not s:\n                continue\n            # Try JSON line\n            if s[0] in [\"{\", \"[\"]:\n                try:\n                    data = json.loads(s)\n                    roots.extend(extract_root_paths(data))\n                    continue\n                except Exception:\n                    pass\n            # Fallback: treat as plain text and extract any token that looks like a ROOT file\n            # e.g. \"root://.../file.root\" or \"/eos/.../file.root\"\n            m = re.findall(r\"(\\S+?\\.root(?:\\?\\S+)?)\", s)\n            roots.extend(m)\n\n    kind = \"jsonl_or_text\"\n    return roots, kind\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T10:01:55.458924Z","iopub.execute_input":"2026-02-16T10:01:55.459208Z","iopub.status.idle":"2026-02-16T10:01:55.470912Z","shell.execute_reply.started":"2026-02-16T10:01:55.459178Z","shell.execute_reply":"2026-02-16T10:01:55.470197Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Cell 5 — Fast manifest builder (escape-aware, early stop)\nimport re\n\nROOT_TOKEN_RE = re.compile(r'(\\S+?\\.root(?:\\?\\S+)?)')\n\ndef clean_root_token(s: str) -> str:\n    s = s.strip().strip('\",]}')         # remove JSON punctuation\n    s = s.replace('\\\\/', '/')           # unescape slashes: \\/ -> /\n    return s\n\ndef parse_index_fast(path, max_paths=200):\n    out = []\n    with path.open(\"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n        for line in f:\n            hits = ROOT_TOKEN_RE.findall(line)\n            for h in hits:\n                h = clean_root_token(h)\n                if \".root\" in h:\n                    out.append(h)\n                    if len(out) >= max_paths:\n                        return out\n    return out\n\nall_roots = []\nparse_meta = []\n\nMAX_PATHS_PER_INDEX = 200\nfor p in index_files:\n    roots_part = parse_index_fast(p, max_paths=MAX_PATHS_PER_INDEX)\n    parse_meta.append({\"index_file\": str(p), \"n_root_paths_sampled\": len(roots_part)})\n    all_roots.extend(roots_part)\n\nmeta_df = pd.DataFrame(parse_meta)\nmeta_df, len(all_roots)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T10:01:55.471913Z","iopub.execute_input":"2026-02-16T10:01:55.472235Z","iopub.status.idle":"2026-02-16T10:10:57.449387Z","shell.execute_reply.started":"2026-02-16T10:01:55.472204Z","shell.execute_reply":"2026-02-16T10:10:57.448255Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/3600206667.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mMAX_PATHS_PER_INDEX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindex_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mroots_part\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_index_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_paths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_PATHS_PER_INDEX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mparse_meta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"index_file\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_root_paths_sampled\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroots_part\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mall_roots\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroots_part\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_55/3600206667.py\u001b[0m in \u001b[0;36mparse_index_fast\u001b[0;34m(path, max_paths)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mhits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mROOT_TOKEN_RE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhits\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_root_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":5},{"cell_type":"code","source":"print(\"Example tokens:\", all_roots[:5])\nprint(meta_df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T10:10:57.450171Z","iopub.status.idle":"2026-02-16T10:10:57.450479Z","shell.execute_reply.started":"2026-02-16T10:10:57.450357Z","shell.execute_reply":"2026-02-16T10:10:57.450375Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 6 — Clean & de-duplicate ROOT paths\ndef normalize_path(s):\n    s = s.strip().strip('\"').strip(\"'\")\n    # Some indices include EOS paths without protocol. If you already have root:// paths, keep them.\n    # If it's a /eos/opendata/... path, you can turn it into root://eospublic.cern.ch//eos/opendata/...\n    if s.startswith(\"/eos/opendata/\"):\n        return \"root://eospublic.cern.ch//\" + s.lstrip(\"/\")\n    return s\n\nroots = [normalize_path(r) for r in all_roots]\nroots = [r for r in roots if r.endswith(\".root\") or \".root?\" in r]\nroots = pd.Series(roots).drop_duplicates().tolist()\n\nlen(roots), roots[:5]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T10:10:57.451509Z","iopub.status.idle":"2026-02-16T10:10:57.451785Z","shell.execute_reply.started":"2026-02-16T10:10:57.451663Z","shell.execute_reply":"2026-02-16T10:10:57.451688Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 7 — Save manifest (useful for debugging & reproducibility)\nmanifest = pd.DataFrame({\"root_file\": roots})\nmanifest_path = Path(\"/kaggle/working/root_files_manifest.csv\")\nmanifest.to_csv(manifest_path, index=False)\nmanifest_path, manifest.head()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Quick sanity checks\n\nWe now:\n1. pick a small deterministic sample of ROOT files\n2. open one file to inspect available TTrees (usually: `Events`, sometimes `Runs`, `LuminosityBlocks`)\n3. inspect branches to decide which features are safe to use in EDA\n","metadata":{}},{"cell_type":"code","source":"# Cell 8 — Deterministic sampling of files for EDA\nN_FILES_FOR_EDA = 3   # start tiny\nsample_files = roots[:N_FILES_FOR_EDA]  # deterministic; you can also do random.sample(roots, N_FILES_FOR_EDA)\n\nsample_files\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 9 — Inspect a single file structure (guard)\nif len(sample_files) == 0:\n    raise RuntimeError(\"No ROOT files found. Check Cell 5/6 parsing; print meta_df and show all_roots[:10].\")\n\ntest_file = sample_files[0]\nf = uproot.open(test_file)\nf.keys()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 10 — Inspect Events tree & branch inventory\nevents = f[\"Events\"]\nbranch_names = events.keys()\n\nlen(branch_names), branch_names[:30]\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 11 — Helper to find branches by prefix (Muon_, HLT_, PV_, MET_, etc.)\ndef find_branches(prefix, names):\n    return sorted([n for n in names if n.startswith(prefix)])\n\nfor pref in [\"Muon_\", \"HLT_\", \"PV_\", \"MET_\", \"Jet_\", \"Electron_\", \"run\", \"luminosityBlock\", \"event\"]:\n    hits = [pref] if pref in branch_names else find_branches(pref, branch_names)\n    print(pref, \"->\", len(hits))\n    print(hits[:20], \"\\n\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Load a small event sample (EDA slice)\n\nWe will read a limited number of entries so EDA runs fast.  \nIf you see memory errors, reduce `ENTRY_STOP` or restrict to fewer branches.\n","metadata":{}},{"cell_type":"code","source":"# Cell 12 — Choose EDA branches (keep this minimal at first)\n# NanoAOD branch names are flat, like Muon_pt, Muon_eta (jagged arrays).\nBASE_BRANCHES = [\"run\", \"luminosityBlock\", \"event\", \"PV_npvs\", \"MET_pt\", \"MET_phi\"]\nMUON_BRANCHES = [\n    \"Muon_pt\", \"Muon_eta\", \"Muon_phi\", \"Muon_charge\",\n    \"Muon_tightId\", \"Muon_mediumId\",\n    \"Muon_pfRelIso03_all\", \"Muon_dxy\", \"Muon_dz\"\n]\n# Trigger inventory can be large; we’ll read a filtered set later.\n\nwanted = [b for b in (BASE_BRANCHES + MUON_BRANCHES) if b in branch_names]\nmissing = sorted(set(BASE_BRANCHES + MUON_BRANCHES) - set(wanted))\n\nwanted, missing[:20], len(missing)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 13 — Read arrays from one file (small slice)\nENTRY_STOP = 200_000  # adjust as needed\n\narr = events.arrays(wanted, entry_stop=ENTRY_STOP, library=\"ak\")\n{ k: (arr[k].type if k in arr.fields else None) for k in arr.fields }\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 14 — Event-level EDA tables\ndf_evt = pd.DataFrame({\n    \"run\": ak.to_numpy(arr[\"run\"]),\n    \"lumi\": ak.to_numpy(arr[\"luminosityBlock\"]),\n    \"event\": ak.to_numpy(arr[\"event\"]),\n    \"PV_npvs\": ak.to_numpy(arr[\"PV_npvs\"]) if \"PV_npvs\" in arr.fields else np.nan,\n    \"MET_pt\": ak.to_numpy(arr[\"MET_pt\"]) if \"MET_pt\" in arr.fields else np.nan,\n})\n\ndf_evt.describe(include=\"all\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 15 — Run/lumi coverage in the slice\ndf_evt[[\"run\", \"lumi\"]].value_counts().head(10)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 16 — Muon multiplicity distribution\nmu_n = ak.num(arr[\"Muon_pt\"])\nmu_n_pd = pd.Series(ak.to_numpy(mu_n), name=\"nMuon\")\n\nmu_n_pd.value_counts().sort_index().head(20), mu_n_pd.describe()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 17 — Basic muon kinematics (flatten all muons in the slice)\nmu_pt = ak.flatten(arr[\"Muon_pt\"])\nmu_eta = ak.flatten(arr[\"Muon_eta\"])\nmu_iso = ak.flatten(arr[\"Muon_pfRelIso03_all\"]) if \"Muon_pfRelIso03_all\" in arr.fields else None\n\nmu_summary = pd.DataFrame({\n    \"Muon_pt\": ak.to_numpy(mu_pt),\n    \"Muon_eta\": ak.to_numpy(mu_eta),\n    \"Muon_pfRelIso03_all\": ak.to_numpy(mu_iso) if mu_iso is not None else np.nan\n}).describe()\n\nmu_summary\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 18 — Quick plots (matplotlib)\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(7,4))\nplt.hist(ak.to_numpy(mu_pt), bins=100, range=(0, 200), histtype=\"step\")\nplt.xlabel(\"Muon pT [GeV]\")\nplt.ylabel(\"Muons / bin\")\nplt.title(\"Muon pT (slice)\")\nplt.show()\n\nplt.figure(figsize=(7,4))\nplt.hist(ak.to_numpy(mu_eta), bins=60, range=(-3, 3), histtype=\"step\")\nplt.xlabel(\"Muon eta\")\nplt.ylabel(\"Muons / bin\")\nplt.title(\"Muon eta (slice)\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Dimuon EDA (physics sanity check)\n\nA recruiter/engineer will trust your pipeline more if you demonstrate a correct dimuon invariant mass spectrum.  \nWe build opposite-sign muon pairs and plot the mass distribution; you should see structures consistent with known resonances in collision data.\n","metadata":{}},{"cell_type":"code","source":"# Cell 19 — Build dimuon pairs and invariant mass\nMUON_MASS = 0.105658  # GeV\n\nmu = vector.zip({\n    \"pt\": arr[\"Muon_pt\"],\n    \"eta\": arr[\"Muon_eta\"],\n    \"phi\": arr[\"Muon_phi\"],\n    \"mass\": ak.ones_like(arr[\"Muon_pt\"]) * MUON_MASS,\n    \"charge\": arr[\"Muon_charge\"],\n})\n\n# Basic quality selection (adjust after you inspect data):\n# - at least mediumId OR tightId if available\nqual = None\nif \"Muon_mediumId\" in arr.fields:\n    qual = (arr[\"Muon_mediumId\"] == 1)\nelif \"Muon_tightId\" in arr.fields:\n    qual = (arr[\"Muon_tightId\"] == 1)\nelse:\n    qual = ak.ones_like(arr[\"Muon_pt\"], dtype=bool)\n\nmu_sel = mu[qual]\n\npairs = ak.combinations(mu_sel, 2, fields=[\"m1\", \"m2\"])\nos_pairs = pairs[(pairs.m1.charge * pairs.m2.charge) < 0]\n\ndimu = os_pairs.m1 + os_pairs.m2\nm_mumu = ak.flatten(dimu.mass)\n\nlen(m_mumu), ak.to_numpy(m_mumu[:10])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 20 — Plot dimuon mass spectrum\nplt.figure(figsize=(8,4))\nplt.hist(ak.to_numpy(m_mumu), bins=200, range=(0, 200), histtype=\"step\")\nplt.xlabel(\"m(μ⁺μ⁻) [GeV]\")\nplt.ylabel(\"Pairs / bin\")\nplt.title(\"Opposite-sign dimuon invariant mass (slice)\")\nplt.yscale(\"log\")\nplt.show()\n\n# Zoom around Z peak\nplt.figure(figsize=(8,4))\nplt.hist(ak.to_numpy(m_mumu), bins=120, range=(60, 120), histtype=\"step\")\nplt.xlabel(\"m(μ⁺μ⁻) [GeV]\")\nplt.ylabel(\"Pairs / bin\")\nplt.title(\"Zoom: Z region\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Trigger inventory (HLT_) EDA\n\nWe’ll discover which `HLT_` branches exist in this file and then compute simple “fired fraction” estimates in our slice.\n","metadata":{}},{"cell_type":"code","source":"# Cell 21 — Enumerate HLT branches (from this file)\nhlt_branches = find_branches(\"HLT_\", branch_names)\nlen(hlt_branches), hlt_branches[:40]\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 22 — Read a small subset of HLT branches (filter to muon-ish names)\n# Keep only muon-related triggers to reduce I/O\nhlt_mu = [b for b in hlt_branches if (\"Mu\" in b or \"mu\" in b)][:60]  # cap for speed\n\nwanted2 = wanted + [b for b in hlt_mu if b not in wanted]\narr2 = events.arrays(wanted2, entry_stop=ENTRY_STOP, library=\"ak\")\n\n# Fired fraction table\nhlt_rate = []\nfor b in hlt_mu:\n    if b in arr2.fields:\n        frac = float(ak.mean(arr2[b]))\n        hlt_rate.append((b, frac))\n\nhlt_rate_df = pd.DataFrame(hlt_rate, columns=[\"HLT_path\", \"fired_fraction_in_slice\"]).sort_values(\n    \"fired_fraction_in_slice\", ascending=False\n)\n\nhlt_rate_df.head(25)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Scale EDA to multiple ROOT files\n\nNow we repeat EDA across a few files to check stability (no single-file artifacts).  \nWe will:\n- read a small number of events from each file\n- compute summary metrics (nMuon mean, MET mean, dimuon-pair count, etc.)\n","metadata":{}},{"cell_type":"code","source":"# Cell 23 — Multi-file EDA summarizer\ndef summarize_file(root_path, entry_stop=100_000):\n    f = uproot.open(root_path)\n    t = f[\"Events\"]\n\n    # Keep branches minimal\n    branches = [b for b in [\"run\",\"luminosityBlock\",\"PV_npvs\",\"MET_pt\",\"Muon_pt\",\"Muon_eta\",\"Muon_phi\",\"Muon_charge\",\"Muon_mediumId\",\"Muon_tightId\"] if b in t.keys()]\n    a = t.arrays(branches, entry_stop=entry_stop, library=\"ak\")\n\n    nMuon = ak.num(a[\"Muon_pt\"])\n    mu_pt = ak.flatten(a[\"Muon_pt\"])\n\n    # Opposite-sign dimuons count (fast approximation)\n    mu_charge = a[\"Muon_charge\"]\n    # Count OS pairs by brute-force combinations (ok for small entry_stop)\n    mu_vec = vector.zip({\n        \"pt\": a[\"Muon_pt\"],\n        \"eta\": a[\"Muon_eta\"],\n        \"phi\": a[\"Muon_phi\"],\n        \"mass\": ak.ones_like(a[\"Muon_pt\"]) * MUON_MASS,\n        \"charge\": mu_charge,\n    })\n    pairs = ak.combinations(mu_vec, 2, fields=[\"m1\",\"m2\"])\n    os_pairs = pairs[(pairs.m1.charge * pairs.m2.charge) < 0]\n    nOSPairs = ak.num(os_pairs.m1)\n\n    out = {\n        \"file\": root_path,\n        \"nEvents\": len(a[\"run\"]) if \"run\" in a.fields else len(a[\"Muon_pt\"]),\n        \"run_min\": int(ak.min(a[\"run\"])) if \"run\" in a.fields else None,\n        \"run_max\": int(ak.max(a[\"run\"])) if \"run\" in a.fields else None,\n        \"nMuon_mean\": float(ak.mean(nMuon)),\n        \"nMuon_p95\": float(np.quantile(ak.to_numpy(nMuon), 0.95)),\n        \"mu_pt_mean\": float(ak.mean(mu_pt)),\n        \"mu_pt_p95\": float(np.quantile(ak.to_numpy(mu_pt), 0.95)),\n        \"MET_mean\": float(ak.mean(a[\"MET_pt\"])) if \"MET_pt\" in a.fields else np.nan,\n        \"nOSPairs_mean\": float(ak.mean(nOSPairs)),\n    }\n    return out\n\nsummaries = []\nfor fp in tqdm(sample_files, desc=\"Summarizing files\"):\n    summaries.append(summarize_file(fp, entry_stop=80_000))\n\nsum_df = pd.DataFrame(summaries)\nsum_df\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 24 — Save EDA summary\nsum_path = Path(\"/kaggle/working/eda_file_summaries.csv\")\nsum_df.to_csv(sum_path, index=False)\nsum_path\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Next step after EDA (prepare for the project)\n\nAfter you confirm:\n- your dimuon mass spectrum looks sensible\n- muon multiplicities are stable across files\n- you understand which HLT paths exist and have non-trivial fired fractions\n\n…then you can lock the project objective:\n**“Explainable trigger emulation + drift monitoring”**:\n- choose 3–6 HLT paths as labels\n- build a Parquet training table from a validated run/lumi selection\n- train an interpretable baseline + GBDT\n- add drift detection over run/lumi blocks\n","metadata":{}},{"cell_type":"code","source":"# Cell 25 — (Optional) Export a small Kaggle-ready Parquet slice for ML iteration\n# This is NOT your final dataset, just a development slice.\n\nout_parquet = Path(\"/kaggle/working/dev_slice.parquet\")\n\n# Flatten per-muon rows (common ML format). Keep run/lumi/event as keys.\n# NOTE: this duplicates event-level info for each muon; that’s fine for quick iteration.\nflat = ak.zip({\n    \"run\": arr2[\"run\"],\n    \"lumi\": arr2[\"luminosityBlock\"],\n    \"event\": arr2[\"event\"],\n    \"PV_npvs\": arr2[\"PV_npvs\"] if \"PV_npvs\" in arr2.fields else ak.zeros_like(arr2[\"run\"]),\n    \"MET_pt\": arr2[\"MET_pt\"] if \"MET_pt\" in arr2.fields else ak.zeros_like(arr2[\"run\"]),\n    \"Muon_pt\": arr2[\"Muon_pt\"],\n    \"Muon_eta\": arr2[\"Muon_eta\"],\n    \"Muon_phi\": arr2[\"Muon_phi\"],\n    \"Muon_charge\": arr2[\"Muon_charge\"],\n    \"Muon_mediumId\": arr2[\"Muon_mediumId\"] if \"Muon_mediumId\" in arr2.fields else ak.zeros_like(arr2[\"Muon_charge\"]),\n    \"Muon_tightId\": arr2[\"Muon_tightId\"] if \"Muon_tightId\" in arr2.fields else ak.zeros_like(arr2[\"Muon_charge\"]),\n    \"Muon_iso\": arr2[\"Muon_pfRelIso03_all\"] if \"Muon_pfRelIso03_all\" in arr2.fields else ak.zeros_like(arr2[\"Muon_pt\"]),\n})\n\nflat_rows = ak.flatten(flat, axis=1)\ndf_flat = ak.to_dataframe(flat_rows).reset_index(drop=True)\n\n# Add a couple of HLT labels (if present)\nfor b in hlt_mu[:10]:\n    if b in arr2.fields:\n        df_flat[b] = np.repeat(ak.to_numpy(arr2[b]), ak.to_numpy(ak.num(arr2[\"Muon_pt\"])))\n\ndf_flat.to_parquet(out_parquet, index=False)\nout_parquet, df_flat.head()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}