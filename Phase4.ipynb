{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14858164,"sourceType":"datasetVersion","datasetId":9504346}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Phase 4 — Event-level evaluation + Multi-label training + Robustness package\n\nGoal of Phase 4:\n1) Convert your **pair-level** table into **event-level** predictions (no “multiple pairs per event” confusion)\n2) Train and evaluate **multiple HLT labels** (1 model per label) with the SAME GroupKFold splits\n3) Add robustness: calibration, threshold selection, drift vs run/lumi, and clean artifacts export\n\nInput: `/kaggle/working/parquet_dimuon/*.parquet` (from Phase 2)\n\nOutput (saved to `/kaggle/working/phase4_artifacts/`):\n- `metrics_per_label.csv` (pair-level + event-level)\n- `thresholds.csv` (operating points)\n- `models/` (joblib models per label)\n- `plots/` (ROC/PR, stability, calibration)\n- `config.json`\n","metadata":{}},{"cell_type":"code","source":"# Cell 1 — Install deps\n!pip -q install lightgbm scikit-learn shap pyarrow fastparquet matplotlib seaborn joblib\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-17T05:56:32.729078Z","iopub.execute_input":"2026-02-17T05:56:32.729704Z","iopub.status.idle":"2026-02-17T05:56:35.857680Z","shell.execute_reply.started":"2026-02-17T05:56:32.729671Z","shell.execute_reply":"2026-02-17T05:56:35.856934Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Cell 2 — Imports & config\nfrom pathlib import Path\nimport glob, json\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.metrics import (\n    roc_auc_score, average_precision_score,\n    roc_curve, precision_recall_curve,\n    brier_score_loss\n)\nfrom sklearn.calibration import calibration_curve\nimport lightgbm as lgb\nimport joblib\n\nSEED = 42\nnp.random.seed(SEED)\n\nPARQUET_DIR = Path(\"/kaggle/input/datasets/katakuricharlotte/parquet-triggeremu/parquet_dimuon\")\nOUT = Path(\"/kaggle/working/phase4_artifacts\")\n(OUT / \"models\").mkdir(parents=True, exist_ok=True)\n(OUT / \"plots\").mkdir(parents=True, exist_ok=True)\n\nparquet_files = sorted(glob.glob(str(PARQUET_DIR / \"*.parquet\")))\nlen(parquet_files), parquet_files[:3]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T05:56:35.859498Z","iopub.execute_input":"2026-02-17T05:56:35.859949Z","iopub.status.idle":"2026-02-17T05:56:41.273876Z","shell.execute_reply.started":"2026-02-17T05:56:35.859921Z","shell.execute_reply":"2026-02-17T05:56:41.273300Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"(1,\n ['/kaggle/input/datasets/katakuricharlotte/parquet-triggeremu/parquet_dimuon/dimuon_shard_000.parquet'])"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# Cell 3 — Load Parquet (scale-friendly)\n# Start with all shards; if too big, cap MAX_FILES.\nMAX_FILES = None  # set e.g. 5 if you want faster iteration\nuse_files = parquet_files if MAX_FILES is None else parquet_files[:MAX_FILES]\n\ndf = pd.concat([pd.read_parquet(p) for p in use_files], ignore_index=True)\ndf.shape, df.head(3)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T05:56:41.274752Z","iopub.execute_input":"2026-02-17T05:56:41.275303Z","iopub.status.idle":"2026-02-17T05:56:41.744511Z","shell.execute_reply.started":"2026-02-17T05:56:41.275277Z","shell.execute_reply":"2026-02-17T05:56:41.743901Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"((1378545, 12),\n       run  lumi       event     m_mumu    pt_mumu  eta_mumu   dR_mumu  \\\n 0  278822   951  1657783742   0.717688  27.446304  0.381257  0.051071   \n 1  278822   951  1657783742  17.536045   5.466623  1.782907  3.233651   \n 2  278822   951  1658163927   0.328497  31.051395 -1.633330  0.008130   \n \n    PV_npvs     MET_pt  HLT_Mu17_Mu8  HLT_Mu17_Mu8_DZ  \\\n 0       12  27.271524             0                0   \n 1       12  27.271524             0                0   \n 2       10  24.150330             0                0   \n \n    HLT_Mu17_TrkIsoVVL_Mu8_TrkIsoVVL_DZ  \n 0                                    0  \n 1                                    0  \n 2                                    1  )"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# Cell 4 — Basic data validation\nrequired_cols = {\"run\",\"lumi\",\"event\"}\nassert required_cols.issubset(df.columns), f\"Missing keys: {required_cols - set(df.columns)}\"\n\nLABELS = sorted([c for c in df.columns if c.startswith(\"HLT_\")])\nassert len(LABELS) > 0, \"No HLT labels found.\"\n\n# event_id for grouping\ndf[\"event_id\"] = df[\"run\"].astype(str) + \":\" + df[\"lumi\"].astype(str) + \":\" + df[\"event\"].astype(str)\n\nprint(\"rows:\", len(df))\nprint(\"unique events:\", df[\"event_id\"].nunique())\nprint(\"labels:\", LABELS[:5], \"... total:\", len(LABELS))\n\n(df[LABELS].mean().sort_values(ascending=False).head(10))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T05:56:41.745470Z","iopub.execute_input":"2026-02-17T05:56:41.745755Z","iopub.status.idle":"2026-02-17T05:56:43.638721Z","shell.execute_reply.started":"2026-02-17T05:56:41.745724Z","shell.execute_reply":"2026-02-17T05:56:43.638164Z"}},"outputs":[{"name":"stdout","text":"rows: 1378545\nunique events: 1171442\nlabels: ['HLT_Mu17_Mu8', 'HLT_Mu17_Mu8_DZ', 'HLT_Mu17_TrkIsoVVL_Mu8_TrkIsoVVL_DZ'] ... total: 3\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"HLT_Mu17_TrkIsoVVL_Mu8_TrkIsoVVL_DZ    0.452260\nHLT_Mu17_Mu8                           0.023145\nHLT_Mu17_Mu8_DZ                        0.020059\ndtype: float64"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"## Phase 4-A: Define features (explainable & stable)\n\nWe keep features that are:\n- physically meaningful (m_mumu, pt_mumu, dR, etc.)\n- simple context (PV_npvs, MET_pt)\nNo IDs and no HLT columns.\n","metadata":{}},{"cell_type":"code","source":"# Cell 5 — Feature set and simple preprocessing\ndrop_cols = set([\"run\",\"lumi\",\"event\",\"event_id\"]) | set(LABELS)\nfeatures = [c for c in df.columns if c not in drop_cols]\n\nX = df[features].copy()\nfor c in X.columns:\n    if X[c].dtype == \"object\":\n        X[c] = pd.to_numeric(X[c], errors=\"coerce\")\n\n# Simple median fill for baseline robustness\nX = X.fillna(X.median(numeric_only=True))\n\nX.shape, features\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T05:56:43.640417Z","iopub.execute_input":"2026-02-17T05:56:43.640659Z","iopub.status.idle":"2026-02-17T05:56:43.794471Z","shell.execute_reply.started":"2026-02-17T05:56:43.640638Z","shell.execute_reply":"2026-02-17T05:56:43.793864Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"((1378545, 6),\n ['m_mumu', 'pt_mumu', 'eta_mumu', 'dR_mumu', 'PV_npvs', 'MET_pt'])"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# Cell 6 — Utility: metrics at pair-level and event-level\ndef safe_auc(y_true, y_score):\n    # Handle edge case where a fold has only one class\n    if len(np.unique(y_true)) < 2:\n        return np.nan\n    return roc_auc_score(y_true, y_score)\n\ndef compute_metrics(y_true, y_score):\n    return {\n        \"roc_auc\": safe_auc(y_true, y_score),\n        \"ap\": average_precision_score(y_true, y_score),\n        \"brier\": brier_score_loss(y_true, y_score),\n        \"pos_rate\": float(np.mean(y_true)),\n        \"n\": int(len(y_true)),\n    }\n\ndef event_level_aggregate(df_part, score_col=\"score\", label_col=\"y\"):\n    # Aggregate pair rows to event-level:\n    # - event score = max(score) (if any pair \"looks like\" it should fire, event fires)\n    # - event label = max(label) (event-level label repeated, so max is safe)\n    g = df_part.groupby(\"event_id\", as_index=False).agg(\n        y=(label_col, \"max\"),\n        score=(score_col, \"max\"),\n        run=(\"run\", \"first\"),\n        lumi=(\"lumi\", \"first\"),\n        event=(\"event\", \"first\"),\n    )\n    return g\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T05:56:43.795231Z","iopub.execute_input":"2026-02-17T05:56:43.795496Z","iopub.status.idle":"2026-02-17T05:56:43.802063Z","shell.execute_reply.started":"2026-02-17T05:56:43.795462Z","shell.execute_reply":"2026-02-17T05:56:43.801263Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## Phase 4-B: Consistent GroupKFold splits (by event)\n\nWe split by `event_id` so that the same collision event never appears in both train and validation.\n","metadata":{}},{"cell_type":"code","source":"# Cell 7 — Prepare GroupKFold splits on unique events (stronger than splitting pair rows)\nevents_unique = df[[\"event_id\"]].drop_duplicates().reset_index(drop=True)\nevent_ids = events_unique[\"event_id\"].values\n\ngkf = GroupKFold(n_splits=5)\n\nsplits = list(gkf.split(event_ids, np.zeros(len(event_ids)), groups=event_ids))\nlen(splits), [ (len(tr), len(va)) for tr,va in splits ]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T05:56:43.802844Z","iopub.execute_input":"2026-02-17T05:56:43.803088Z","iopub.status.idle":"2026-02-17T05:56:47.475243Z","shell.execute_reply.started":"2026-02-17T05:56:43.803068Z","shell.execute_reply":"2026-02-17T05:56:47.474547Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(5,\n [(937153, 234289),\n  (937153, 234289),\n  (937154, 234288),\n  (937154, 234288),\n  (937154, 234288)])"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"# Cell 8 — Map event splits to pair-row indices (so training uses pair rows but validation stays event-disjoint)\nevent_to_fold = {}\nfor fold, (_, va_idx) in enumerate(splits, start=1):\n    for eid in event_ids[va_idx]:\n        event_to_fold[eid] = fold\n\ndf[\"fold\"] = df[\"event_id\"].map(event_to_fold).astype(int)\ndf[\"fold\"].value_counts().sort_index()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T05:56:47.476156Z","iopub.execute_input":"2026-02-17T05:56:47.476465Z","iopub.status.idle":"2026-02-17T05:56:48.817386Z","shell.execute_reply.started":"2026-02-17T05:56:47.476444Z","shell.execute_reply":"2026-02-17T05:56:48.816759Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"fold\n1    275842\n2    275929\n3    275602\n4    275834\n5    275338\nName: count, dtype: int64"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"## Phase 4-C: Train 1 model per label (with class imbalance handling)\n\nWe train LightGBM models with `scale_pos_weight` for imbalance, and we store:\n- per-fold metrics\n- overall OOF predictions\n- event-level metrics after aggregating pair scores to event scores\n","metadata":{}},{"cell_type":"code","source":"# Cell 9 — Training loop for multiple labels\nparams = dict(\n    n_estimators=800,\n    learning_rate=0.05,\n    num_leaves=31,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    random_state=SEED,\n    n_jobs=-1,\n)\n\nall_metrics = []\noof_scores = {}   # label -> oof scores (pair-level)\nmodels = {}\n\nfor label in LABELS:\n    y = df[label].astype(int).values\n\n    # Skip degenerate labels\n    if y.mean() < 1e-4 or y.mean() > 1 - 1e-4:\n        all_metrics.append({\"label\": label, \"note\": \"skipped_degenerate\", \"pos_rate\": float(y.mean())})\n        continue\n\n    oof = np.zeros(len(df), dtype=float)\n\n    for fold in sorted(df[\"fold\"].unique()):\n        tr_mask = df[\"fold\"].values != fold\n        va_mask = df[\"fold\"].values == fold\n\n        X_tr, X_va = X.loc[tr_mask], X.loc[va_mask]\n        y_tr, y_va = y[tr_mask], y[va_mask]\n\n        pos = max(y_tr.sum(), 1)\n        neg = max(len(y_tr) - y_tr.sum(), 1)\n        spw = neg / pos\n\n        clf = lgb.LGBMClassifier(objective=\"binary\", scale_pos_weight=spw, **params)\n        clf.fit(X_tr, y_tr)\n\n        pred = clf.predict_proba(X_va)[:, 1]\n        oof[va_mask] = pred\n\n        m_pair = compute_metrics(y_va, pred)\n        all_metrics.append({\n            \"label\": label,\n            \"fold\": int(fold),\n            \"level\": \"pair\",\n            \"scale_pos_weight\": float(spw),\n            **m_pair\n        })\n\n    # Store OOF\n    oof_scores[label] = oof\n\n    # Train final model on all data\n    pos = max(y.sum(), 1)\n    neg = max(len(y) - y.sum(), 1)\n    spw = neg / pos\n    final_model = lgb.LGBMClassifier(objective=\"binary\", scale_pos_weight=spw, **params)\n    final_model.fit(X, y)\n\n    models[label] = final_model\n    joblib.dump(final_model, OUT / \"models\" / f\"{label}.joblib\")\n\nlen(models), list(models.keys())[:5]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T05:56:48.818284Z","iopub.execute_input":"2026-02-17T05:56:48.818524Z","iopub.status.idle":"2026-02-17T06:03:16.040727Z","shell.execute_reply.started":"2026-02-17T05:56:48.818503Z","shell.execute_reply":"2026-02-17T06:03:16.039993Z"}},"outputs":[{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 25391, number of negative: 1077312\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034308 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 1336\n[LightGBM] [Info] Number of data points in the train set: 1102703, number of used features: 6\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.023026 -> initscore=-3.747830\n[LightGBM] [Info] Start training from score -3.747830\n[LightGBM] [Info] Number of positive: 25554, number of negative: 1077062\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030397 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 1333\n[LightGBM] [Info] Number of data points in the train set: 1102616, number of used features: 6\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.023176 -> initscore=-3.741198\n[LightGBM] [Info] Start training from score -3.741198\n[LightGBM] [Info] Number of positive: 25594, number of negative: 1077349\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009110 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1332\n[LightGBM] [Info] Number of data points in the train set: 1102943, number of used features: 6\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.023205 -> initscore=-3.739901\n[LightGBM] [Info] Start training from score -3.739901\n[LightGBM] [Info] Number of positive: 25618, number of negative: 1077093\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008863 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1333\n[LightGBM] [Info] Number of data points in the train set: 1102711, number of used features: 6\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.023232 -> initscore=-3.738726\n[LightGBM] [Info] Start training from score -3.738726\n[LightGBM] [Info] Number of positive: 25471, number of negative: 1077736\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008971 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1331\n[LightGBM] [Info] Number of data points in the train set: 1103207, number of used features: 6\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.023088 -> initscore=-3.745077\n[LightGBM] [Info] Start training from score -3.745077\n[LightGBM] [Info] Number of positive: 31907, number of negative: 1346638\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042924 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 1333\n[LightGBM] [Info] Number of data points in the train set: 1378545, number of used features: 6\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.023145 -> initscore=-3.742541\n[LightGBM] [Info] Start training from score -3.742541\n[LightGBM] [Info] Number of positive: 22046, number of negative: 1080657\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032423 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 1336\n[LightGBM] [Info] Number of data points in the train set: 1102703, number of used features: 6\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.019993 -> initscore=-3.892193\n[LightGBM] [Info] Start training from score -3.892193\n[LightGBM] [Info] Number of positive: 22124, number of negative: 1080492\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030093 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 1333\n[LightGBM] [Info] Number of data points in the train set: 1102616, number of used features: 6\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020065 -> initscore=-3.888509\n[LightGBM] [Info] Start training from score -3.888509\n[LightGBM] [Info] Number of positive: 22185, number of negative: 1080758\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009152 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1332\n[LightGBM] [Info] Number of data points in the train set: 1102943, number of used features: 6\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020114 -> initscore=-3.886002\n[LightGBM] [Info] Start training from score -3.886002\n[LightGBM] [Info] Number of positive: 22216, number of negative: 1080495\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029949 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 1333\n[LightGBM] [Info] Number of data points in the train set: 1102711, number of used features: 6\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020147 -> initscore=-3.884362\n[LightGBM] [Info] Start training from score -3.884362\n[LightGBM] [Info] Number of positive: 22037, number of negative: 1081170\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008840 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1331\n[LightGBM] [Info] Number of data points in the train set: 1103207, number of used features: 6\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.019975 -> initscore=-3.893076\n[LightGBM] [Info] Start training from score -3.893076\n[LightGBM] [Info] Number of positive: 27652, number of negative: 1350893\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039031 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 1333\n[LightGBM] [Info] Number of data points in the train set: 1378545, number of used features: 6\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020059 -> initscore=-3.888823\n[LightGBM] [Info] Start training from score -3.888823\n[LightGBM] [Info] Number of positive: 498458, number of negative: 604245\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008818 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1336\n[LightGBM] [Info] Number of data points in the train set: 1102703, number of used features: 6\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.452033 -> initscore=-0.192460\n[LightGBM] [Info] Start training from score -0.192460\n[LightGBM] [Info] Number of positive: 498839, number of negative: 603777\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008704 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1333\n[LightGBM] [Info] Number of data points in the train set: 1102616, number of used features: 6\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.452414 -> initscore=-0.190922\n[LightGBM] [Info] Start training from score -0.190922\n[LightGBM] [Info] Number of positive: 498561, number of negative: 604382\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008810 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1332\n[LightGBM] [Info] Number of data points in the train set: 1102943, number of used features: 6\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.452028 -> initscore=-0.192480\n[LightGBM] [Info] Start training from score -0.192480\n[LightGBM] [Info] Number of positive: 499306, number of negative: 603405\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029875 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 1333\n[LightGBM] [Info] Number of data points in the train set: 1102711, number of used features: 6\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.452799 -> initscore=-0.189369\n[LightGBM] [Info] Start training from score -0.189369\n[LightGBM] [Info] Number of positive: 498680, number of negative: 604527\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009494 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1331\n[LightGBM] [Info] Number of data points in the train set: 1103207, number of used features: 6\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.452028 -> initscore=-0.192482\n[LightGBM] [Info] Start training from score -0.192482\n[LightGBM] [Info] Number of positive: 623461, number of negative: 755084\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038173 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 1333\n[LightGBM] [Info] Number of data points in the train set: 1378545, number of used features: 6\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.452260 -> initscore=-0.191543\n[LightGBM] [Info] Start training from score -0.191543\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"(3, ['HLT_Mu17_Mu8', 'HLT_Mu17_Mu8_DZ', 'HLT_Mu17_TrkIsoVVL_Mu8_TrkIsoVVL_DZ'])"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"# Cell 10 — Compute event-level metrics from OOF (per label)\nevent_metrics = []\n\nfor label, oof in oof_scores.items():\n    tmp = df[[\"event_id\",\"run\",\"lumi\",\"event\"]].copy()\n    tmp[\"y\"] = df[label].astype(int).values\n    tmp[\"score\"] = oof\n\n    ev = event_level_aggregate(tmp, score_col=\"score\", label_col=\"y\")\n    m_ev = compute_metrics(ev[\"y\"].values, ev[\"score\"].values)\n\n    event_metrics.append({\"label\": label, \"level\": \"event\", \"fold\": \"OOF\", **m_ev})\n\nevent_metrics_df = pd.DataFrame(event_metrics).sort_values([\"ap\"], ascending=False)\nevent_metrics_df.head(15)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T06:03:16.041849Z","iopub.execute_input":"2026-02-17T06:03:16.042100Z","iopub.status.idle":"2026-02-17T06:03:22.081518Z","shell.execute_reply.started":"2026-02-17T06:03:16.042079Z","shell.execute_reply":"2026-02-17T06:03:22.080858Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                 label  level fold   roc_auc        ap  \\\n2  HLT_Mu17_TrkIsoVVL_Mu8_TrkIsoVVL_DZ  event  OOF  0.854013  0.821139   \n0                         HLT_Mu17_Mu8  event  OOF  0.641999  0.040802   \n1                      HLT_Mu17_Mu8_DZ  event  OOF  0.655972  0.036737   \n\n      brier  pos_rate        n  \n2  0.156055  0.498980  1171442  \n0  0.235345  0.024772  1171442  \n1  0.233206  0.021538  1171442  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>level</th>\n      <th>fold</th>\n      <th>roc_auc</th>\n      <th>ap</th>\n      <th>brier</th>\n      <th>pos_rate</th>\n      <th>n</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>HLT_Mu17_TrkIsoVVL_Mu8_TrkIsoVVL_DZ</td>\n      <td>event</td>\n      <td>OOF</td>\n      <td>0.854013</td>\n      <td>0.821139</td>\n      <td>0.156055</td>\n      <td>0.498980</td>\n      <td>1171442</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>HLT_Mu17_Mu8</td>\n      <td>event</td>\n      <td>OOF</td>\n      <td>0.641999</td>\n      <td>0.040802</td>\n      <td>0.235345</td>\n      <td>0.024772</td>\n      <td>1171442</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HLT_Mu17_Mu8_DZ</td>\n      <td>event</td>\n      <td>OOF</td>\n      <td>0.655972</td>\n      <td>0.036737</td>\n      <td>0.233206</td>\n      <td>0.021538</td>\n      <td>1171442</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"# Cell 11 — Combine and save metrics\nmetrics_df = pd.DataFrame(all_metrics)\nmetrics_out = OUT / \"metrics_per_label.csv\"\nmetrics_df.to_csv(metrics_out, index=False)\n\nevent_out = OUT / \"event_metrics_oof.csv\"\nevent_metrics_df.to_csv(event_out, index=False)\n\nmetrics_out, event_out\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T06:03:22.082374Z","iopub.execute_input":"2026-02-17T06:03:22.082636Z","iopub.status.idle":"2026-02-17T06:03:22.094276Z","shell.execute_reply.started":"2026-02-17T06:03:22.082614Z","shell.execute_reply":"2026-02-17T06:03:22.093619Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"(PosixPath('/kaggle/working/phase4_artifacts/metrics_per_label.csv'),\n PosixPath('/kaggle/working/phase4_artifacts/event_metrics_oof.csv'))"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"## Phase 4-D: Choose operating thresholds (engineering deliverable)\n\nWe pick a threshold for each label based on a target **recall** (efficiency) or based on maximizing F1.\nThis makes the model usable like a trigger/selection component.\n","metadata":{}},{"cell_type":"code","source":"# Cell 12 — Threshold selection (OOF) per label\ndef choose_threshold(y_true, y_score, target_recall=0.95):\n    prec, rec, thr = precision_recall_curve(y_true, y_score)\n    # precision_recall_curve returns thr of length n-1\n    # Find first threshold reaching recall >= target_recall\n    idx = np.where(rec[:-1] >= target_recall)[0]\n    if len(idx) == 0:\n        # fallback: best F1\n        f1 = 2 * (prec * rec) / (prec + rec + 1e-12)\n        best = np.nanargmax(f1)\n        return float(thr[max(best-1, 0)]), float(prec[best]), float(rec[best])\n    i = idx[0]\n    return float(thr[i]), float(prec[i]), float(rec[i])\n\nthreshold_rows = []\nfor label, oof in oof_scores.items():\n    tmp = df[[\"event_id\"]].copy()\n    tmp[\"y\"] = df[label].astype(int).values\n    tmp[\"score\"] = oof\n    ev = event_level_aggregate(tmp, score_col=\"score\", label_col=\"y\")\n\n    th, p, r = choose_threshold(ev[\"y\"].values, ev[\"score\"].values, target_recall=0.95)\n    threshold_rows.append({\"label\": label, \"threshold\": th, \"precision_at_th\": p, \"recall_at_th\": r, \"event_pos_rate\": float(ev[\"y\"].mean())})\n\nthresholds_df = pd.DataFrame(threshold_rows).sort_values(\"event_pos_rate\", ascending=False)\nthresholds_df\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T06:03:22.095084Z","iopub.execute_input":"2026-02-17T06:03:22.095308Z","iopub.status.idle":"2026-02-17T06:03:22.170561Z","shell.execute_reply.started":"2026-02-17T06:03:22.095289Z","shell.execute_reply":"2026-02-17T06:03:22.169448Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/60322071.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"score\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moof\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevent_level_aggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"score\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchoose_threshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_recall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.95\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_55/2584382134.py\u001b[0m in \u001b[0;36mevent_level_aggregate\u001b[0;34m(df_part, score_col, label_col)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# - event score = max(score) (if any pair \"looks like\" it should fire, event fires)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# - event label = max(label) (event-level label repeated, so max is safe)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     g = df_part.groupby(\"event_id\", as_index=False).agg(\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"max\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mscore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"max\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1431\u001b[0m         \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGroupByApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1432\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_dict_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1434\u001b[0m             \u001b[0;31m# GH #52849\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36magg\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_dict_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg_dict_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0;31m# we require a list, but not a 'str'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36magg_dict_like\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0mResult\u001b[0m \u001b[0mof\u001b[0m \u001b[0maggregation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \"\"\"\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg_or_apply_dict_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"agg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m     def compute_dict_like(\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36magg_or_apply_dict_like\u001b[0;34m(self, op_name)\u001b[0m\n\u001b[1;32m   1606\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"as_index\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"as_index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m         ):\n\u001b[0;32m-> 1608\u001b[0;31m             result_index, result_data = self.compute_dict_like(\n\u001b[0m\u001b[1;32m   1609\u001b[0m                 \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mcompute_dict_like\u001b[0;34m(self, op_name, selected_obj, selection, kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0mis_groupby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mDataFrameGroupBy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeriesGroupBy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAggFuncTypeDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_dictlike_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         is_non_unique_col = (\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mnormalize_dictlike_arg\u001b[0;34m(self, how, obj, func)\u001b[0m\n\u001b[1;32m    661\u001b[0m             \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdifference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Column(s) {list(cols)} do not exist\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m         \u001b[0maggregator_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: \"Column(s) ['event', 'lumi', 'run'] do not exist\""],"ename":"KeyError","evalue":"\"Column(s) ['event', 'lumi', 'run'] do not exist\"","output_type":"error"}],"execution_count":13},{"cell_type":"code","source":"# Cell 13 — Save thresholds\nthr_out = OUT / \"thresholds.csv\"\nthresholds_df.to_csv(thr_out, index=False)\nthr_out\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T06:03:22.171074Z","iopub.status.idle":"2026-02-17T06:03:22.171321Z","shell.execute_reply.started":"2026-02-17T06:03:22.171210Z","shell.execute_reply":"2026-02-17T06:03:22.171223Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Phase 4-E: Plots (ROC/PR + calibration) for top labels\nWe generate plots for the top 3 labels by event-level AP (OOF).\n","metadata":{}},{"cell_type":"code","source":"# Cell 14 — Plot helpers\ndef save_roc_pr(y_true, y_score, title, out_prefix):\n    fpr, tpr, _ = roc_curve(y_true, y_score)\n    prec, rec, _ = precision_recall_curve(y_true, y_score)\n\n    plt.figure(figsize=(6,5))\n    plt.plot(fpr, tpr)\n    plt.plot([0,1],[0,1],\"--\",alpha=0.5)\n    plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\")\n    plt.title(f\"ROC: {title}\")\n    plt.tight_layout()\n    plt.savefig(out_prefix + \"_roc.png\", dpi=150)\n    plt.show()\n\n    plt.figure(figsize=(6,5))\n    plt.plot(rec, prec)\n    plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\")\n    plt.title(f\"PR: {title}\")\n    plt.tight_layout()\n    plt.savefig(out_prefix + \"_pr.png\", dpi=150)\n    plt.show()\n\ndef save_calibration(y_true, y_score, title, out_prefix):\n    frac_pos, mean_pred = calibration_curve(y_true, y_score, n_bins=10, strategy=\"quantile\")\n    plt.figure(figsize=(6,5))\n    plt.plot(mean_pred, frac_pos, marker=\"o\")\n    plt.plot([0,1],[0,1],\"--\",alpha=0.5)\n    plt.xlabel(\"Mean predicted probability\")\n    plt.ylabel(\"Fraction of positives\")\n    plt.title(f\"Calibration: {title}\")\n    plt.tight_layout()\n    plt.savefig(out_prefix + \"_cal.png\", dpi=150)\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T06:03:22.171985Z","iopub.status.idle":"2026-02-17T06:03:22.172308Z","shell.execute_reply.started":"2026-02-17T06:03:22.172184Z","shell.execute_reply":"2026-02-17T06:03:22.172199Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 15 — Generate plots for top labels\ntop_labels = event_metrics_df.sort_values(\"ap\", ascending=False)[\"label\"].head(3).tolist()\ntop_labels\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T06:03:22.173468Z","iopub.status.idle":"2026-02-17T06:03:22.173738Z","shell.execute_reply.started":"2026-02-17T06:03:22.173624Z","shell.execute_reply":"2026-02-17T06:03:22.173638Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 16 — Plot OOF event-level ROC/PR/Calibration for top labels\nfor label in top_labels:\n    oof = oof_scores[label]\n    tmp = df[[\"event_id\"]].copy()\n    tmp[\"y\"] = df[label].astype(int).values\n    tmp[\"score\"] = oof\n    ev = event_level_aggregate(tmp, score_col=\"score\", label_col=\"y\")\n\n    title = f\"{label} (event-level OOF)\"\n    out_prefix = str(OUT / \"plots\" / label)\n\n    save_roc_pr(ev[\"y\"].values, ev[\"score\"].values, title, out_prefix)\n    save_calibration(ev[\"y\"].values, ev[\"score\"].values, title, out_prefix)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T06:03:22.175101Z","iopub.status.idle":"2026-02-17T06:03:22.175395Z","shell.execute_reply.started":"2026-02-17T06:03:22.175276Z","shell.execute_reply":"2026-02-17T06:03:22.175291Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Phase 4-F: Drift monitoring (event-level) vs run and lumi\nWe look at:\n- label rate vs run bin\n- mean score vs run bin\n\n(You can later add lumi-level or time-ordered drift tests.)\n","metadata":{}},{"cell_type":"code","source":"# Cell 17 — Drift table & plots for the main label (best AP)\nmain_label = top_labels[0]\noof = oof_scores[main_label]\n\ntmp = df[[\"event_id\",\"run\",\"lumi\",\"event\"]].copy()\ntmp[\"y\"] = df[main_label].astype(int).values\ntmp[\"score\"] = oof\nev = event_level_aggregate(tmp, score_col=\"score\", label_col=\"y\")\n\nev[\"run_bin\"] = pd.cut(ev[\"run\"], bins=10)\n\nstab = ev.groupby(\"run_bin\").agg(\n    n=(\"y\",\"size\"),\n    y_rate=(\"y\",\"mean\"),\n    score_mean=(\"score\",\"mean\")\n).reset_index()\n\nstab\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T06:03:22.176511Z","iopub.status.idle":"2026-02-17T06:03:22.176738Z","shell.execute_reply.started":"2026-02-17T06:03:22.176632Z","shell.execute_reply":"2026-02-17T06:03:22.176645Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 18 — Plot drift vs run bins (drop empty bins)\nstab2 = stab[stab[\"n\"] > 0].copy()\n\nplt.figure(figsize=(10,4))\nplt.plot(stab2[\"run_bin\"].astype(str), stab2[\"y_rate\"], marker=\"o\")\nplt.xticks(rotation=45, ha=\"right\")\nplt.ylabel(\"Event label rate\")\nplt.title(f\"Label rate vs run bin — {main_label}\")\nplt.tight_layout()\nplt.savefig(OUT / \"plots\" / f\"{main_label}_drift_labelrate.png\", dpi=150)\nplt.show()\n\nplt.figure(figsize=(10,4))\nplt.plot(stab2[\"run_bin\"].astype(str), stab2[\"score_mean\"], marker=\"o\")\nplt.xticks(rotation=45, ha=\"right\")\nplt.ylabel(\"Mean predicted score (OOF)\")\nplt.title(f\"Mean score vs run bin — {main_label}\")\nplt.tight_layout()\nplt.savefig(OUT / \"plots\" / f\"{main_label}_drift_score.png\", dpi=150)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T06:03:22.178336Z","iopub.status.idle":"2026-02-17T06:03:22.178658Z","shell.execute_reply.started":"2026-02-17T06:03:22.178512Z","shell.execute_reply":"2026-02-17T06:03:22.178540Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Phase 4-G: Robust SHAP cell (no confusing warnings)\n\nSHAP output shapes can differ for LightGBM binary classification (sometimes list, sometimes array),\nso we handle both safely before plotting.\n","metadata":{}},{"cell_type":"code","source":"# Cell 19 — SHAP (safe handling)\nimport shap\n\nlabel = main_label\nmodel = models[label]\n\n# Use a small sample of rows for speed\nsample_n = min(5000, len(X))\nidx = np.random.choice(len(X), sample_n, replace=False)\nX_s = X.iloc[idx]\n\nexplainer = shap.TreeExplainer(model)\nsv = explainer.shap_values(X_s)\n\n# Some versions return list for binary class; take the positive-class component if needed. [web:159]\nif isinstance(sv, list) and len(sv) == 2:\n    sv_use = sv[1]\nelse:\n    sv_use = sv\n\nshap.summary_plot(sv_use, X_s, show=False)\nplt.tight_layout()\nplt.savefig(OUT / \"plots\" / f\"{label}_shap_summary.png\", dpi=150)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T06:03:22.179459Z","iopub.status.idle":"2026-02-17T06:03:22.179727Z","shell.execute_reply.started":"2026-02-17T06:03:22.179604Z","shell.execute_reply":"2026-02-17T06:03:22.179619Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 20 — Save config + final directory listing\nconfig = {\n    \"seed\": SEED,\n    \"n_rows\": int(len(df)),\n    \"n_unique_events\": int(df[\"event_id\"].nunique()),\n    \"features\": list(X.columns),\n    \"labels_trained\": list(models.keys()),\n    \"top_labels_by_event_ap\": top_labels\n}\nwith open(OUT / \"config.json\", \"w\") as f:\n    json.dump(config, f, indent=2)\n\nsorted([p.name for p in OUT.iterdir()]), sorted([p.name for p in (OUT/\"plots\").iterdir()])[:10]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T06:03:22.180851Z","iopub.status.idle":"2026-02-17T06:03:22.181210Z","shell.execute_reply.started":"2026-02-17T06:03:22.181020Z","shell.execute_reply":"2026-02-17T06:03:22.181041Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# summary\n\n- Multi-label models saved under `phase4_artifacts/models/`\n- Pair-level CV metrics and event-level OOF metrics (`metrics_per_label.csv`, `event_metrics_oof.csv`)\n- Operating thresholds (`thresholds.csv`)\n- ROC/PR/Calibration/Drift plots for top labels\n- SHAP explanation plot for the main label\n","metadata":{}}]}