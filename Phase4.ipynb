{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14858164,"sourceType":"datasetVersion","datasetId":9504346}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Phase 4 — Event-level evaluation + Multi-label training + Robustness package\n\nGoal of Phase 4:\n1) Convert your **pair-level** table into **event-level** predictions (no “multiple pairs per event” confusion)\n2) Train and evaluate **multiple HLT labels** (1 model per label) with the SAME GroupKFold splits\n3) Add robustness: calibration, threshold selection, drift vs run/lumi, and clean artifacts export\n\nInput: `/kaggle/working/parquet_dimuon/*.parquet` (from Phase 2)\n\nOutput (saved to `/kaggle/working/phase4_artifacts/`):\n- `metrics_per_label.csv` (pair-level + event-level)\n- `thresholds.csv` (operating points)\n- `models/` (joblib models per label)\n- `plots/` (ROC/PR, stability, calibration)\n- `config.json`\n","metadata":{}},{"cell_type":"code","source":"# Cell 1 — Install deps\n!pip -q install lightgbm scikit-learn shap pyarrow fastparquet matplotlib seaborn joblib\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-17T05:52:34.014202Z","iopub.execute_input":"2026-02-17T05:52:34.014454Z","iopub.status.idle":"2026-02-17T05:52:38.823509Z","shell.execute_reply.started":"2026-02-17T05:52:34.014424Z","shell.execute_reply":"2026-02-17T05:52:38.822642Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Cell 2 — Imports & config\nfrom pathlib import Path\nimport glob, json\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.metrics import (\n    roc_auc_score, average_precision_score,\n    roc_curve, precision_recall_curve,\n    brier_score_loss\n)\nfrom sklearn.calibration import calibration_curve\nimport lightgbm as lgb\nimport joblib\n\nSEED = 42\nnp.random.seed(SEED)\n\nPARQUET_DIR = Path(\"/kaggle/input/datasets/katakuricharlotte/parquet-triggeremu/parquet_dimuon\")\nOUT = Path(\"/kaggle/working/phase4_artifacts\")\n(OUT / \"models\").mkdir(parents=True, exist_ok=True)\n(OUT / \"plots\").mkdir(parents=True, exist_ok=True)\n\nparquet_files = sorted(glob.glob(str(PARQUET_DIR / \"*.parquet\")))\nlen(parquet_files), parquet_files[:3]\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}