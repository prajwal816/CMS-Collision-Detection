{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14857240,"sourceType":"datasetVersion","datasetId":9503642},{"sourceId":14858164,"sourceType":"datasetVersion","datasetId":9504346}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Phase 3 — Modeling + Explainability + Drift checks (Trigger Emulation)\n\nInput: Parquet shards produced in Phase 2 (`/kaggle/working/parquet_dimuon/`).\n\nOutput:\n- A baseline model to emulate one HLT path (start with the balanced one)\n- Proper evaluation with **grouped splits by event** (no leakage)\n- Explainability (feature importance + SHAP if available)\n- Stability/drift plots vs run and lumi\n- Saved model + metrics + figures\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-16T13:03:45.743263Z","iopub.execute_input":"2026-02-16T13:03:45.744074Z","iopub.status.idle":"2026-02-16T13:03:45.749493Z","shell.execute_reply.started":"2026-02-16T13:03:45.744044Z","shell.execute_reply":"2026-02-16T13:03:45.748469Z"}},"outputs":[{"traceback":["\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_55/3689652338.py\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    Input: Parquet shards produced in Phase 2 (`/kaggle/working/parquet_dimuon/`).\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"],"ename":"SyntaxError","evalue":"invalid syntax (3689652338.py, line 3)","output_type":"error"}],"execution_count":2},{"cell_type":"code","source":"# Cell 1 — Install deps\n!pip -q install lightgbm scikit-learn shap pyarrow fastparquet matplotlib seaborn\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T13:03:45.750046Z","iopub.status.idle":"2026-02-16T13:03:45.750288Z","shell.execute_reply.started":"2026-02-16T13:03:45.750170Z","shell.execute_reply":"2026-02-16T13:03:45.750184Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 2 — Imports & config\nfrom pathlib import Path\nimport glob\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.metrics import roc_auc_score, average_precision_score, precision_recall_curve, roc_curve\n\nimport lightgbm as lgb\n\nSEED = 42\nnp.random.seed(SEED)\n\nPARQUET_DIR = Path(\"/kaggle/input/datasets/katakuricharlotte/parquet-triggeremu/parquet_dimuon\")\nparquet_files = sorted(glob.glob(str(PARQUET_DIR / \"*.parquet\")))\n\nlen(parquet_files), parquet_files[:3]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T13:03:45.751404Z","iopub.status.idle":"2026-02-16T13:03:45.751623Z","shell.execute_reply.started":"2026-02-16T13:03:45.751520Z","shell.execute_reply":"2026-02-16T13:03:45.751532Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 3 — Load Parquet (start small; scale later)\n# If you only produced one shard, this still works.\nMAX_FILES = 5  # increase later\nuse_files = parquet_files[:MAX_FILES]\n\ndf = pd.concat([pd.read_parquet(p) for p in use_files], ignore_index=True)\ndf.shape, df.columns.tolist()[:30]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T13:03:45.752932Z","iopub.status.idle":"2026-02-16T13:03:45.753257Z","shell.execute_reply.started":"2026-02-16T13:03:45.753104Z","shell.execute_reply":"2026-02-16T13:03:45.753127Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 4 — Sanity checks (schema, missingness, duplicates)\nprint(df.dtypes.head(20))\ndisplay(df.head(5))\n\n# Missing values summary (top)\nna = df.isna().mean().sort_values(ascending=False)\nna.head(20)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T13:03:45.765364Z","iopub.execute_input":"2026-02-16T13:03:45.765636Z","iopub.status.idle":"2026-02-16T13:03:45.774769Z","shell.execute_reply.started":"2026-02-16T13:03:45.765601Z","shell.execute_reply":"2026-02-16T13:03:45.773552Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/3647708165.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Cell 4 — Sanity checks (schema, missingness, duplicates)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Missing values summary (top)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"],"ename":"NameError","evalue":"name 'df' is not defined","output_type":"error"}],"execution_count":3},{"cell_type":"code","source":"# Cell 5 — Ensure labels exist and inspect label rates\nLABELS = [c for c in df.columns if c.startswith(\"HLT_\")]\nLABELS[:10], len(LABELS)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T13:03:45.775444Z","iopub.status.idle":"2026-02-16T13:03:45.775734Z","shell.execute_reply.started":"2026-02-16T13:03:45.775575Z","shell.execute_reply":"2026-02-16T13:03:45.775596Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 6 — Pick a primary label (balanced one first)\n# From your output: HLT_Mu17_TrkIsoVVL_Mu8_TrkIsoVVL_DZ ~ 0.45, others ~ 0.02\nTARGET = \"HLT_Mu17_TrkIsoVVL_Mu8_TrkIsoVVL_DZ\" if \"HLT_Mu17_TrkIsoVVL_Mu8_TrkIsoVVL_DZ\" in df.columns else LABELS[0]\ny = df[TARGET].astype(int)\n\ny.mean(), TARGET\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T13:03:45.777430Z","iopub.status.idle":"2026-02-16T13:03:45.777766Z","shell.execute_reply.started":"2026-02-16T13:03:45.777605Z","shell.execute_reply":"2026-02-16T13:03:45.777625Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 7 — Build event groups to avoid leakage\n# IMPORTANT: your rows are dimuon pairs; multiple rows share same (run,lumi,event).\n# We'll group-split by a stable event_id.\ndf[\"event_id\"] = df[\"run\"].astype(str) + \":\" + df[\"lumi\"].astype(str) + \":\" + df[\"event\"].astype(str)\ngroups = df[\"event_id\"].values\n\ndf[\"event_id\"].nunique(), len(df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T13:03:45.778937Z","iopub.status.idle":"2026-02-16T13:03:45.779271Z","shell.execute_reply.started":"2026-02-16T13:03:45.779101Z","shell.execute_reply":"2026-02-16T13:03:45.779121Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 8 — Define feature set (explainable, physics-friendly)\n# Keep only engineered dimuon + simple event context; avoid labels and identifiers.\ndrop_cols = set([\"run\", \"lumi\", \"event\", \"event_id\"]) | set(LABELS)\ncandidate_features = [c for c in df.columns if c not in drop_cols]\n\n# LightGBM can't handle object; enforce numeric\nX = df[candidate_features].copy()\nfor c in X.columns:\n    if X[c].dtype == \"object\":\n        X[c] = pd.to_numeric(X[c], errors=\"coerce\")\n\n# Basic imputation: fill NaNs with median (simple + explainable baseline)\nX = X.fillna(X.median(numeric_only=True))\n\nX.shape, X.columns.tolist()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T13:03:45.780545Z","iopub.status.idle":"2026-02-16T13:03:45.780953Z","shell.execute_reply.started":"2026-02-16T13:03:45.780726Z","shell.execute_reply":"2026-02-16T13:03:45.780746Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 9 — Quick EDA of key features (distributions + correlations)\nkey_feats = [c for c in [\"m_mumu\", \"pt_mumu\", \"eta_mumu\", \"dR_mumu\", \"PV_npvs\", \"MET_pt\"] if c in X.columns]\n\nfig, axes = plt.subplots(2, 3, figsize=(14, 7))\naxes = axes.ravel()\nfor i, c in enumerate(key_feats[:6]):\n    sns.histplot(X[c], bins=60, ax=axes[i], kde=False)\n    axes[i].set_title(c)\nplt.tight_layout()\nplt.show()\n\n# Correlation heatmap (small set)\nif len(key_feats) >= 2:\n    plt.figure(figsize=(6,5))\n    sns.heatmap(pd.DataFrame(X[key_feats]).corr(), annot=True, fmt=\".2f\", cmap=\"viridis\")\n    plt.title(\"Feature correlations (selected)\")\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T13:03:45.782280Z","iopub.status.idle":"2026-02-16T13:03:45.782552Z","shell.execute_reply.started":"2026-02-16T13:03:45.782415Z","shell.execute_reply":"2026-02-16T13:03:45.782428Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 10 — Define evaluation helpers\ndef eval_fold(y_true, y_score):\n    out = {}\n    out[\"roc_auc\"] = roc_auc_score(y_true, y_score)\n    out[\"ap\"] = average_precision_score(y_true, y_score)\n    return out\n\ndef plot_curves(y_true, y_score, title_suffix=\"\"):\n    fpr, tpr, _ = roc_curve(y_true, y_score)\n    prec, rec, _ = precision_recall_curve(y_true, y_score)\n\n    plt.figure(figsize=(6,5))\n    plt.plot(fpr, tpr)\n    plt.plot([0,1],[0,1], \"--\", alpha=0.5)\n    plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\")\n    plt.title(f\"ROC {title_suffix}\")\n    plt.show()\n\n    plt.figure(figsize=(6,5))\n    plt.plot(rec, prec)\n    plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\")\n    plt.title(f\"PR {title_suffix}\")\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T13:03:45.783499Z","iopub.status.idle":"2026-02-16T13:03:45.783710Z","shell.execute_reply.started":"2026-02-16T13:03:45.783608Z","shell.execute_reply":"2026-02-16T13:03:45.783621Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 11 — GroupKFold training (no leakage)\n# GroupKFold enforces that the same event_id never appears in both train and val. [web:141]\ngkf = GroupKFold(n_splits=5)\n\nparams = dict(\n    n_estimators=400,\n    learning_rate=0.05,\n    num_leaves=31,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    random_state=SEED,\n    n_jobs=-1\n)\n\nfold_metrics = []\noof = np.zeros(len(df), dtype=float)\n\nfor fold, (tr_idx, va_idx) in enumerate(gkf.split(X, y, groups=groups), start=1):\n    X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n    y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n\n    # Handle imbalance: LightGBM suggests scale_pos_weight or is_unbalance for binary. [web:152]\n    pos = max(y_tr.sum(), 1)\n    neg = max((len(y_tr) - y_tr.sum()), 1)\n    spw = neg / pos\n\n    clf = lgb.LGBMClassifier(\n        objective=\"binary\",\n        scale_pos_weight=spw,\n        **params\n    )\n    clf.fit(X_tr, y_tr)\n\n    yhat = clf.predict_proba(X_va)[:, 1]\n    oof[va_idx] = yhat\n\n    m = eval_fold(y_va, yhat)\n    m[\"fold\"] = fold\n    m[\"scale_pos_weight\"] = spw\n    fold_metrics.append(m)\n    print(f\"Fold {fold}:\", m)\n\nmetrics_df = pd.DataFrame(fold_metrics)\nmetrics_df, metrics_df[[\"roc_auc\",\"ap\"]].mean()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T13:03:45.784433Z","iopub.status.idle":"2026-02-16T13:03:45.784714Z","shell.execute_reply.started":"2026-02-16T13:03:45.784537Z","shell.execute_reply":"2026-02-16T13:03:45.784557Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 12 — OOF curves\nplot_curves(y, oof, title_suffix=f\"(OOF) {TARGET}\")\nprint(\"OOF ROC-AUC:\", roc_auc_score(y, oof))\nprint(\"OOF AP:\", average_precision_score(y, oof))  # AP summarizes PR curve. [web:150]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T13:03:45.873622Z","iopub.execute_input":"2026-02-16T13:03:45.873932Z","iopub.status.idle":"2026-02-16T13:03:45.880153Z","shell.execute_reply.started":"2026-02-16T13:03:45.873873Z","shell.execute_reply":"2026-02-16T13:03:45.878958Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/3844567876.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Cell 12 — OOF curves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_curves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moof\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle_suffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"(OOF) {TARGET}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OOF ROC-AUC:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moof\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OOF AP:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage_precision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moof\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# AP summarizes PR curve. [web:150]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'plot_curves' is not defined"],"ename":"NameError","evalue":"name 'plot_curves' is not defined","output_type":"error"}],"execution_count":4},{"cell_type":"code","source":"# Cell 13 — Feature importance (explainable baseline)\n# Train final model on all data (for importance + saving)\npos = max(y.sum(), 1)\nneg = max((len(y) - y.sum()), 1)\nspw = neg / pos\n\nfinal_model = lgb.LGBMClassifier(objective=\"binary\", scale_pos_weight=spw, **params)\nfinal_model.fit(X, y)\n\nimp = pd.DataFrame({\n    \"feature\": X.columns,\n    \"importance\": final_model.feature_importances_\n}).sort_values(\"importance\", ascending=False)\n\nimp.head(20)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T13:03:45.881165Z","iopub.status.idle":"2026-02-16T13:03:45.881456Z","shell.execute_reply.started":"2026-02-16T13:03:45.881319Z","shell.execute_reply":"2026-02-16T13:03:45.881339Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 14 — Plot top importances\ntopn = 25\nplt.figure(figsize=(8, 8))\nsns.barplot(data=imp.head(topn), x=\"importance\", y=\"feature\")\nplt.title(f\"Top {topn} feature importances — {TARGET}\")\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T13:03:45.882308Z","iopub.status.idle":"2026-02-16T13:03:45.882599Z","shell.execute_reply.started":"2026-02-16T13:03:45.882477Z","shell.execute_reply":"2026-02-16T13:03:45.882494Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 15 — Optional: SHAP explanations (may take time; run after baseline works)\nimport shap\n\n# Use a small sample for speed\nsample_n = min(5000, len(X))\nsample_idx = np.random.choice(len(X), sample_n, replace=False)\n\nexplainer = shap.TreeExplainer(final_model)\nshap_values = explainer.shap_values(X.iloc[sample_idx])\n\nshap.summary_plot(shap_values, X.iloc[sample_idx], show=False)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T13:03:45.883500Z","iopub.status.idle":"2026-02-16T13:03:45.883794Z","shell.execute_reply.started":"2026-02-16T13:03:45.883632Z","shell.execute_reply":"2026-02-16T13:03:45.883653Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Drift / stability checks \n\nWe test if the model behaves consistently across run and lumi:\n- predicted positive rate vs run\n- average score vs run\n- AP/ROC-AUC vs run (coarse bins)\n\nThis is crucial because your labels are event-level triggers and your rows are dimuon pairs.\n","metadata":{}},{"cell_type":"code","source":"# Cell 16 — Add OOF score back to df for stability plots\ndf_eval = df[[\"run\",\"lumi\",\"event\"]].copy()\ndf_eval[\"y\"] = y.values\ndf_eval[\"score\"] = oof\n\n# Bin by run (coarse)\ndf_eval[\"run_bin\"] = pd.cut(df_eval[\"run\"], bins=10)\n\nstab = df_eval.groupby(\"run_bin\").agg(\n    n=(\"y\",\"size\"),\n    y_rate=(\"y\",\"mean\"),\n    score_mean=(\"score\",\"mean\")\n).reset_index()\n\nstab\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T13:03:45.885359Z","iopub.status.idle":"2026-02-16T13:03:45.885671Z","shell.execute_reply.started":"2026-02-16T13:03:45.885549Z","shell.execute_reply":"2026-02-16T13:03:45.885564Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 17 — Plot stability vs run bins\nplt.figure(figsize=(10,4))\nplt.plot(stab[\"run_bin\"].astype(str), stab[\"y_rate\"], marker=\"o\")\nplt.xticks(rotation=45, ha=\"right\")\nplt.ylabel(\"Label rate\")\nplt.title(f\"Label rate vs run bins — {TARGET}\")\nplt.tight_layout()\nplt.show()\n\nplt.figure(figsize=(10,4))\nplt.plot(stab[\"run_bin\"].astype(str), stab[\"score_mean\"], marker=\"o\")\nplt.xticks(rotation=45, ha=\"right\")\nplt.ylabel(\"Mean predicted score (OOF)\")\nplt.title(f\"Mean score vs run bins — {TARGET}\")\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T13:03:45.887375Z","iopub.status.idle":"2026-02-16T13:03:45.887594Z","shell.execute_reply.started":"2026-02-16T13:03:45.887489Z","shell.execute_reply":"2026-02-16T13:03:45.887502Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 18 — Save artifacts (model + metrics + importance)\nimport joblib, json\n\nOUT = Path(\"/kaggle/working/phase3_artifacts\")\nOUT.mkdir(parents=True, exist_ok=True)\n\njoblib.dump(final_model, OUT / \"lgbm_model.joblib\")\nmetrics_df.to_csv(OUT / \"cv_metrics.csv\", index=False)\nimp.to_csv(OUT / \"feature_importance.csv\", index=False)\n\nwith open(OUT / \"config.json\", \"w\") as f:\n    json.dump({\"target\": TARGET, \"features\": list(X.columns), \"seed\": SEED, \"params\": params}, f, indent=2)\n\nstr(OUT), sorted([p.name for p in OUT.iterdir()])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T13:03:45.888690Z","iopub.status.idle":"2026-02-16T13:03:45.889033Z","shell.execute_reply.started":"2026-02-16T13:03:45.888845Z","shell.execute_reply":"2026-02-16T13:03:45.888865Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n\n- No data leakage: grouped splits by (run,lumi,event)\n- Metrics: ROC-AUC + **Average Precision** (better for imbalance) [web:150]\n- Explainability: feature importance (+ SHAP optional)\n- Stability: score and label-rate vs run bins\n- Reproducible outputs saved in `/kaggle/working/phase3_artifacts`\n","metadata":{}}]}