{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14857240,"sourceType":"datasetVersion","datasetId":9503642},{"sourceId":14858164,"sourceType":"datasetVersion","datasetId":9504346}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Phase 3 — Modeling + Explainability + Drift checks (Trigger Emulation)\n\n**Input:**  \nParquet shards produced in Phase 2 (`/kaggle/working/parquet_dimuon/`)\n\n**Output:**\n\n- A baseline model to emulate one HLT path (start with the balanced one)\n- Proper evaluation with grouped splits by event (no leakage)\n- Explainability (feature importance + SHAP if available)\n- Stability/drift plots vs run and lumi\n- Saved model + metrics + figures\n","metadata":{}},{"cell_type":"code","source":"# Cell 1 — Install deps\n!pip -q install lightgbm scikit-learn shap pyarrow fastparquet matplotlib seaborn\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T13:09:54.331282Z","iopub.execute_input":"2026-02-16T13:09:54.332032Z","iopub.status.idle":"2026-02-16T13:09:58.808916Z","shell.execute_reply.started":"2026-02-16T13:09:54.332005Z","shell.execute_reply":"2026-02-16T13:09:58.808190Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 2 — Imports & config\nfrom pathlib import Path\nimport glob\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.metrics import roc_auc_score, average_precision_score, precision_recall_curve, roc_curve\n\nimport lightgbm as lgb\n\nSEED = 42\nnp.random.seed(SEED)\n\nPARQUET_DIR = Path(\"/kaggle/input/datasets/katakuricharlotte/parquet-triggeremu/parquet_dimuon\")\nparquet_files = sorted(glob.glob(str(PARQUET_DIR / \"*.parquet\")))\n\nlen(parquet_files), parquet_files[:3]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T13:09:58.810390Z","iopub.execute_input":"2026-02-16T13:09:58.810617Z","iopub.status.idle":"2026-02-16T13:10:04.748397Z","shell.execute_reply.started":"2026-02-16T13:09:58.810593Z","shell.execute_reply":"2026-02-16T13:10:04.747660Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 3 — Load Parquet (start small; scale later)\n# If you only produced one shard, this still works.\nMAX_FILES = 5  # increase later\nuse_files = parquet_files[:MAX_FILES]\n\ndf = pd.concat([pd.read_parquet(p) for p in use_files], ignore_index=True)\ndf.shape, df.columns.tolist()[:30]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T13:10:04.749309Z","iopub.execute_input":"2026-02-16T13:10:04.749889Z","iopub.status.idle":"2026-02-16T13:10:05.640762Z","shell.execute_reply.started":"2026-02-16T13:10:04.749855Z","shell.execute_reply":"2026-02-16T13:10:05.640215Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 4 — Sanity checks (schema, missingness, duplicates)\nprint(df.dtypes.head(20))\ndisplay(df.head(5))\n\n# Missing values summary (top)\nna = df.isna().mean().sort_values(ascending=False)\nna.head(20)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T13:10:05.642551Z","iopub.execute_input":"2026-02-16T13:10:05.642775Z","iopub.status.idle":"2026-02-16T13:10:05.697520Z","shell.execute_reply.started":"2026-02-16T13:10:05.642755Z","shell.execute_reply":"2026-02-16T13:10:05.696757Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 5 — Ensure labels exist and inspect label rates\nLABELS = [c for c in df.columns if c.startswith(\"HLT_\")]\nLABELS[:10], len(LABELS)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T13:10:05.698481Z","iopub.execute_input":"2026-02-16T13:10:05.698713Z","iopub.status.idle":"2026-02-16T13:10:05.703591Z","shell.execute_reply.started":"2026-02-16T13:10:05.698692Z","shell.execute_reply":"2026-02-16T13:10:05.703096Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 6 — Pick a primary label (balanced one first)\n# From your output: HLT_Mu17_TrkIsoVVL_Mu8_TrkIsoVVL_DZ ~ 0.45, others ~ 0.02\nTARGET = \"HLT_Mu17_TrkIsoVVL_Mu8_TrkIsoVVL_DZ\" if \"HLT_Mu17_TrkIsoVVL_Mu8_TrkIsoVVL_DZ\" in df.columns else LABELS[0]\ny = df[TARGET].astype(int)\n\ny.mean(), TARGET\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T13:10:05.704365Z","iopub.execute_input":"2026-02-16T13:10:05.704610Z","iopub.status.idle":"2026-02-16T13:10:05.725471Z","shell.execute_reply.started":"2026-02-16T13:10:05.704590Z","shell.execute_reply":"2026-02-16T13:10:05.724689Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 7 — Build event groups to avoid leakage\n# IMPORTANT: your rows are dimuon pairs; multiple rows share same (run,lumi,event).\n# We'll group-split by a stable event_id.\ndf[\"event_id\"] = df[\"run\"].astype(str) + \":\" + df[\"lumi\"].astype(str) + \":\" + df[\"event\"].astype(str)\ngroups = df[\"event_id\"].values\n\ndf[\"event_id\"].nunique(), len(df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T13:10:05.726482Z","iopub.execute_input":"2026-02-16T13:10:05.727052Z","iopub.status.idle":"2026-02-16T13:10:07.598573Z","shell.execute_reply.started":"2026-02-16T13:10:05.727030Z","shell.execute_reply":"2026-02-16T13:10:07.597825Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 8 — Define feature set (explainable, physics-friendly)\n# Keep only engineered dimuon + simple event context; avoid labels and identifiers.\ndrop_cols = set([\"run\", \"lumi\", \"event\", \"event_id\"]) | set(LABELS)\ncandidate_features = [c for c in df.columns if c not in drop_cols]\n\n# LightGBM can't handle object; enforce numeric\nX = df[candidate_features].copy()\nfor c in X.columns:\n    if X[c].dtype == \"object\":\n        X[c] = pd.to_numeric(X[c], errors=\"coerce\")\n\n# Basic imputation: fill NaNs with median (simple + explainable baseline)\nX = X.fillna(X.median(numeric_only=True))\n\nX.shape, X.columns.tolist()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T13:10:07.599647Z","iopub.execute_input":"2026-02-16T13:10:07.600057Z","iopub.status.idle":"2026-02-16T13:10:07.762774Z","shell.execute_reply.started":"2026-02-16T13:10:07.600026Z","shell.execute_reply":"2026-02-16T13:10:07.762197Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 9 — Quick EDA of key features (distributions + correlations)\nkey_feats = [c for c in [\"m_mumu\", \"pt_mumu\", \"eta_mumu\", \"dR_mumu\", \"PV_npvs\", \"MET_pt\"] if c in X.columns]\n\nfig, axes = plt.subplots(2, 3, figsize=(14, 7))\naxes = axes.ravel()\nfor i, c in enumerate(key_feats[:6]):\n    sns.histplot(X[c], bins=60, ax=axes[i], kde=False)\n    axes[i].set_title(c)\nplt.tight_layout()\nplt.show()\n\n# Correlation heatmap (small set)\nif len(key_feats) >= 2:\n    plt.figure(figsize=(6,5))\n    sns.heatmap(pd.DataFrame(X[key_feats]).corr(), annot=True, fmt=\".2f\", cmap=\"viridis\")\n    plt.title(\"Feature correlations (selected)\")\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T13:10:07.763607Z","iopub.execute_input":"2026-02-16T13:10:07.764040Z","iopub.status.idle":"2026-02-16T13:10:13.949889Z","shell.execute_reply.started":"2026-02-16T13:10:07.764017Z","shell.execute_reply":"2026-02-16T13:10:13.949249Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 10 — Define evaluation helpers\ndef eval_fold(y_true, y_score):\n    out = {}\n    out[\"roc_auc\"] = roc_auc_score(y_true, y_score)\n    out[\"ap\"] = average_precision_score(y_true, y_score)\n    return out\n\ndef plot_curves(y_true, y_score, title_suffix=\"\"):\n    fpr, tpr, _ = roc_curve(y_true, y_score)\n    prec, rec, _ = precision_recall_curve(y_true, y_score)\n\n    plt.figure(figsize=(6,5))\n    plt.plot(fpr, tpr)\n    plt.plot([0,1],[0,1], \"--\", alpha=0.5)\n    plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\")\n    plt.title(f\"ROC {title_suffix}\")\n    plt.show()\n\n    plt.figure(figsize=(6,5))\n    plt.plot(rec, prec)\n    plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\")\n    plt.title(f\"PR {title_suffix}\")\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T13:10:13.951825Z","iopub.execute_input":"2026-02-16T13:10:13.952115Z","iopub.status.idle":"2026-02-16T13:10:13.958054Z","shell.execute_reply.started":"2026-02-16T13:10:13.952091Z","shell.execute_reply":"2026-02-16T13:10:13.957345Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 11 — GroupKFold training (no leakage)\n# GroupKFold enforces that the same event_id never appears in both train and val. [web:141]\ngkf = GroupKFold(n_splits=5)\n\nparams = dict(\n    n_estimators=400,\n    learning_rate=0.05,\n    num_leaves=31,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    random_state=SEED,\n    n_jobs=-1\n)\n\nfold_metrics = []\noof = np.zeros(len(df), dtype=float)\n\nfor fold, (tr_idx, va_idx) in enumerate(gkf.split(X, y, groups=groups), start=1):\n    X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n    y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n\n    # Handle imbalance: LightGBM suggests scale_pos_weight or is_unbalance for binary. [web:152]\n    pos = max(y_tr.sum(), 1)\n    neg = max((len(y_tr) - y_tr.sum()), 1)\n    spw = neg / pos\n\n    clf = lgb.LGBMClassifier(\n        objective=\"binary\",\n        scale_pos_weight=spw,\n        **params\n    )\n    clf.fit(X_tr, y_tr)\n\n    yhat = clf.predict_proba(X_va)[:, 1]\n    oof[va_idx] = yhat\n\n    m = eval_fold(y_va, yhat)\n    m[\"fold\"] = fold\n    m[\"scale_pos_weight\"] = spw\n    fold_metrics.append(m)\n    print(f\"Fold {fold}:\", m)\n\nmetrics_df = pd.DataFrame(fold_metrics)\nmetrics_df, metrics_df[[\"roc_auc\",\"ap\"]].mean()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T13:10:13.958877Z","iopub.execute_input":"2026-02-16T13:10:13.959116Z","iopub.status.idle":"2026-02-16T13:11:30.765541Z","shell.execute_reply.started":"2026-02-16T13:10:13.959088Z","shell.execute_reply":"2026-02-16T13:11:30.764952Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 12 — OOF curves\nplot_curves(y, oof, title_suffix=f\"(OOF) {TARGET}\")\nprint(\"OOF ROC-AUC:\", roc_auc_score(y, oof))\nprint(\"OOF AP:\", average_precision_score(y, oof))  # AP summarizes PR curve. [web:150]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T13:11:30.766675Z","iopub.execute_input":"2026-02-16T13:11:30.767256Z","iopub.status.idle":"2026-02-16T13:11:32.357052Z","shell.execute_reply.started":"2026-02-16T13:11:30.767216Z","shell.execute_reply":"2026-02-16T13:11:32.356347Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 13 — Feature importance (explainable baseline)\n# Train final model on all data (for importance + saving)\npos = max(y.sum(), 1)\nneg = max((len(y) - y.sum()), 1)\nspw = neg / pos\n\nfinal_model = lgb.LGBMClassifier(objective=\"binary\", scale_pos_weight=spw, **params)\nfinal_model.fit(X, y)\n\nimp = pd.DataFrame({\n    \"feature\": X.columns,\n    \"importance\": final_model.feature_importances_\n}).sort_values(\"importance\", ascending=False)\n\nimp.head(20)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T13:11:32.357951Z","iopub.execute_input":"2026-02-16T13:11:32.358195Z","iopub.status.idle":"2026-02-16T13:11:47.186206Z","shell.execute_reply.started":"2026-02-16T13:11:32.358173Z","shell.execute_reply":"2026-02-16T13:11:47.185563Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 14 — Plot top importances\ntopn = 25\nplt.figure(figsize=(8, 8))\nsns.barplot(data=imp.head(topn), x=\"importance\", y=\"feature\")\nplt.title(f\"Top {topn} feature importances — {TARGET}\")\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T13:11:47.186984Z","iopub.execute_input":"2026-02-16T13:11:47.188014Z","iopub.status.idle":"2026-02-16T13:11:47.344568Z","shell.execute_reply.started":"2026-02-16T13:11:47.187984Z","shell.execute_reply":"2026-02-16T13:11:47.343972Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 15 — Optional: SHAP explanations (may take time; run after baseline works)\nimport shap\n\n# Use a small sample for speed\nsample_n = min(5000, len(X))\nsample_idx = np.random.choice(len(X), sample_n, replace=False)\n\nexplainer = shap.TreeExplainer(final_model)\nshap_values = explainer.shap_values(X.iloc[sample_idx])\n\nshap.summary_plot(shap_values, X.iloc[sample_idx], show=False)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T13:11:47.345687Z","iopub.execute_input":"2026-02-16T13:11:47.345957Z","iopub.status.idle":"2026-02-16T13:11:54.351816Z","shell.execute_reply.started":"2026-02-16T13:11:47.345928Z","shell.execute_reply":"2026-02-16T13:11:54.351110Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Drift / stability checks \n\nWe test if the model behaves consistently across run and lumi:\n- predicted positive rate vs run\n- average score vs run\n- AP/ROC-AUC vs run (coarse bins)\n\nThis is crucial because your labels are event-level triggers and your rows are dimuon pairs.\n","metadata":{}},{"cell_type":"code","source":"# Cell 16 — Add OOF score back to df for stability plots\ndf_eval = df[[\"run\",\"lumi\",\"event\"]].copy()\ndf_eval[\"y\"] = y.values\ndf_eval[\"score\"] = oof\n\n# Bin by run (coarse)\ndf_eval[\"run_bin\"] = pd.cut(df_eval[\"run\"], bins=10)\n\nstab = df_eval.groupby(\"run_bin\").agg(\n    n=(\"y\",\"size\"),\n    y_rate=(\"y\",\"mean\"),\n    score_mean=(\"score\",\"mean\")\n).reset_index()\n\nstab\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T13:11:54.352647Z","iopub.execute_input":"2026-02-16T13:11:54.353327Z","iopub.status.idle":"2026-02-16T13:11:54.456452Z","shell.execute_reply.started":"2026-02-16T13:11:54.353302Z","shell.execute_reply":"2026-02-16T13:11:54.455703Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 17 — Plot stability vs run bins\nplt.figure(figsize=(10,4))\nplt.plot(stab[\"run_bin\"].astype(str), stab[\"y_rate\"], marker=\"o\")\nplt.xticks(rotation=45, ha=\"right\")\nplt.ylabel(\"Label rate\")\nplt.title(f\"Label rate vs run bins — {TARGET}\")\nplt.tight_layout()\nplt.show()\n\nplt.figure(figsize=(10,4))\nplt.plot(stab[\"run_bin\"].astype(str), stab[\"score_mean\"], marker=\"o\")\nplt.xticks(rotation=45, ha=\"right\")\nplt.ylabel(\"Mean predicted score (OOF)\")\nplt.title(f\"Mean score vs run bins — {TARGET}\")\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T13:11:54.457424Z","iopub.execute_input":"2026-02-16T13:11:54.457650Z","iopub.status.idle":"2026-02-16T13:11:54.756897Z","shell.execute_reply.started":"2026-02-16T13:11:54.457630Z","shell.execute_reply":"2026-02-16T13:11:54.756179Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 18 — Save artifacts (model + metrics + importance)\nimport joblib, json\n\nOUT = Path(\"/kaggle/working/phase3_artifacts\")\nOUT.mkdir(parents=True, exist_ok=True)\n\njoblib.dump(final_model, OUT / \"lgbm_model.joblib\")\nmetrics_df.to_csv(OUT / \"cv_metrics.csv\", index=False)\nimp.to_csv(OUT / \"feature_importance.csv\", index=False)\n\nwith open(OUT / \"config.json\", \"w\") as f:\n    json.dump({\"target\": TARGET, \"features\": list(X.columns), \"seed\": SEED, \"params\": params}, f, indent=2)\n\nstr(OUT), sorted([p.name for p in OUT.iterdir()])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T13:11:54.757976Z","iopub.execute_input":"2026-02-16T13:11:54.758248Z","iopub.status.idle":"2026-02-16T13:11:54.802170Z","shell.execute_reply.started":"2026-02-16T13:11:54.758215Z","shell.execute_reply":"2026-02-16T13:11:54.801543Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n\n- No data leakage: grouped splits by (run,lumi,event)\n- Metrics: ROC-AUC + **Average Precision** (better for imbalance) [web:150]\n- Explainability: feature importance (+ SHAP optional)\n- Stability: score and label-rate vs run bins\n- Reproducible outputs saved in `/kaggle/working/phase3_artifacts`\n","metadata":{}}]}